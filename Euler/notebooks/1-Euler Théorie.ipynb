{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"1-Euler Théorie.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"oDYtuLbM5eYV"},"source":["# Euler project"]},{"cell_type":"markdown","source":["$$\n","\\partial_t w + \\partial_x {F(w)} =  0\n","$$\n","exemple $F(w)=w^2/2$.\n","\n"],"metadata":{"id":"BKG3ZwoCcYT0"}},{"cell_type":"markdown","source":["$$\n","w^{n+1}_i  = w^n_i -  \\frac {\\delta_t}{\\delta_x} [F(w^n_{i+\\frac 12}) - F(w^n_{i- \\frac 12}) ]\n","$$"],"metadata":{"id":"tiR2mjCdclPJ"}},{"cell_type":"markdown","source":[""],"metadata":{"id":"gDAfMSKvdBkJ"}},{"cell_type":"code","metadata":{"id":"oRwA41jq1EG8"},"source":["import numpy as np\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cFC-eS36XlgN"},"source":["## Introduction généraliste\n","\n","* Léo : viscosité  spaciale: diffuser en fonction de la forme de la fonction. Ex fort graident\n","    * local ou global\n","    * on regarde les fonctions une à une. \n","    * Selon les régime plysique, tu veux plus difuser les choses les plus rapides. Pas nécessaire en GD: il y a déjà de la viscosité physique.  Alors qu'en élément fini on est obligé de faire les 2\n","\n","\n","* Euler: viscosité physique. Couplé. Qui ne dépend que des interaction entre les variables. quel phénomène est le plus rapide, le plus fort. \n","    * On s'interdit de regarder globallement.\n","    * On diffuse en rho, rhoV, E. \n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"uGWsWZuufmtZ"},"source":["### EDP\n","\n","On se donne une fonction $F:\\mathbb R^n \\to \\mathbb R^n $. \n","\n","On cherche une fonction $(x,t)\\to w(x,t)\\in \\mathbb R^n$ qui satisfait à l'EDP suivante:\n","$$ \\tag{EDP}\n"," \\partial_t w = - \\partial_x F(w)\n","$$\n","L'évolution en temps de $w$ est donnée par une dérivée spaciale de $F(w)$ que l'on appelle naturellement le flux.  "]},{"cell_type":"markdown","metadata":{"id":"-yvJ56efg2kR"},"source":["### Schéma\n","\n","* On a une discrétisation temporelle $t_0,t_1,...$.  \n","* On a une discrétisation spaciale $x_0,x_1,...$.  \n","* On condisère aussi les points spaciaux du milieu. $x_{i+\\frac 12}=(x_i + x_{i+1})/2$\n","\n","On note\n","* $w^n_i = w(x_i,t_n)$\n","* $w^n_{i+\\frac 12} = w(x_{i+\\frac 12},t_n)$\n","\n","L'équation $(EDP)$ s'écrit alors: \n","$$\n","\\frac 1{\\delta_t} [w^{n+1}_i - w^n_i ] = - \\frac 1{\\delta_x} [F(w^n_{i+\\frac 12}) - F(w^n_{i- \\frac 12}) ]\n","$$\n","ou encore\n","$$\n","w^{n+1}_i  = w^n_i -  \\frac {\\delta_t}{\\delta_x} [F(w^n_{i+\\frac 12}) - F(w^n_{i- \\frac 12}) ]\n","$$\n","Ce schémat nous permettra d'évoluer en temps. \n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ajf9Xm7gldix"},"source":["## Trouver une fonction interpolante \n","\n","***NB:*** Par la suite, et jusqu'à la nouvelle intervention du temps, on se fixe un temps $t_n$. Et abrège $v_i^n,w_i^n$ par $v_i,w_i$. \n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["### Approximation du Flux"],"metadata":{"id":"HGt5YxNtAVd6"}},{"cell_type":"markdown","source":["Il nous faut maintenant une fonction qui nous permette de rester toujours sur le même maillage. \n","On suppose l'existance d'une fonction $F_?$ à deux variable telle que\n","$$\n","F_?(w_i,w_{i+1}) \\approx  F(w_{i+\\frac 12})\n","$$\n","$F_?$ est appelé le flux numérique. Le choix de cette fonction est très important. Tout le travail qui suit consite à trouver un bon candidat. Un mauvais choix crée des problèmes de stabilité: les erreur  se propagent quand on applique successivement le schéma numérique.\n","\n","***Variante:*** On peut imaginer une fonction à plus de variable:\n","$$\n","F_?(w_{i-1},w_i,w_{i+1},w_{i+2}) \\approx  F(w_{i+\\frac 12})\n","$$"],"metadata":{"id":"iAbP4ol4BZYy"}},{"cell_type":"markdown","source":["### ou approximation d'une différence de Flux"],"metadata":{"id":"F_UgSRemBaUf"}},{"cell_type":"markdown","source":[" \n","Le terme droit du schéma numérique est:\n","$$\n"," w_i -  \\frac {\\delta_t}{\\delta_x} [F(w_{i+\\frac 12})-F(w_{i-\\frac 12})]\n","$$\n","\n","Pour garder une maillage constant, une autre solution est d'essayer de trouver directement une fonction $F\\!F_?$ telle que\n","$$\n","F\\!F_?(w_{i-1},w_i,w_{i+1}) \\approx F(w_{i+\\frac 12})-F(w_{i-\\frac 12})\n","$$\n","***variante:*** Et pourquoi pas une fonction à plus de variables\n","$$\n","F\\!F_?(w_{i-2},w_{i-1},w_i,w_{i+1},w_{i+2}) \\approx F(w_{i+\\frac 12})-F(w_{i-\\frac 12})\n","$$\n","\n"],"metadata":{"id":"cBoF0MmO_gE5"}},{"cell_type":"markdown","source":["Anticipons: dans nos expérimentation, l'approximation directe de la différence de flux par des réseaux de neurones donne des résultats moins bons en terme de stabilité.  "],"metadata":{"id":"JWofmKrbC_a2"}},{"cell_type":"markdown","source":["### Mauvais candidat naturel"],"metadata":{"id":"9wMdoAo3C7vs"}},{"cell_type":"markdown","source":["Un premier candidat naturel pour le flux numérique est de prendre la moyenne:\n","$$\n","F_?(w_i,w_{i+1}) = \\frac{F(w_i)+F(w_{i+1})}{ 2} \n","$$\n","Mais il est très instable dans le temps. \n","\n","\n","Pour améliorer sa stabilité, une technique classique consiste à jouter un terme à la moyenne:\n","$$\n","F_?(w_i,w_{i+1}) = \\frac{F(w_i)+F(w_{i+1})}{ 2}  + A(w_i,w_{i+1})(w_{i+1}-w_i)\n","$$\n","La fonction $A$ est souvent prise bilinéaire. "],"metadata":{"id":"uBHfFv1l_1-h"}},{"cell_type":"markdown","metadata":{"id":"50aKOIxOmgQm"},"source":["### Le flux HLL\n","\n","Pour simplifier, notons $F_i=F(w_i)$. Le Flux HLL  est donné par la formule:\n","$$\n","F_{HLL} (w_i,w_{i+1})=\n","\\begin{cases}\n","F_{i} & \\text{si } \\lambda_{i} \\geq 0 \\\\\n","\\frac{\\lambda_{i+1} F_{i} - \\lambda_{i} F_{i+1} }{\\lambda_{i+1}-\\lambda_{i}} +\n","\\frac{\\lambda_{i+1}\\lambda_{i} (w_{i+1} -  w_{i}) }{\\lambda_{i+1}-\\lambda_{i}}\n"," & \\text{si } \\lambda_i<0< \\lambda_{i+1} \\\\\n"," F_{i+1} &\\text{si } \\lambda_{i+1}\\leq 0 \n","\\\\\n","\\end{cases}\n","$$\n","où $\\lambda_i=...$.\n"]},{"cell_type":"markdown","source":["### Notre candidat\n","\n","\n","C'est un très bon candidat. Notre travaille consiste à l'améliorer avec un terme additif:\n","$$\n","F_{\\theta} (w_i,w_{i+1})=F_{HLL} (w_i,w_{i+1})+ A_\\theta(w_i,w_{i+1})\n","$$\n","et nous testerons aussi des solutions à 4 variables:\n","$$\n","F_{\\theta} (w_{i-1},w_i,w_{i+1},w_{i+2})=F_{HLL} (w_i,w_{i+1})+ A_\\theta(w_{i-1},w_i,w_{i+1},w_{i+2})\n","$$\n","où plus (6,8,...)"],"metadata":{"id":"nILTooYWE3v8"}},{"cell_type":"markdown","metadata":{"id":"ZKcyJAxFphkW"},"source":["## Apprentissage supervisé. \n","\n","Grace à une grille très fine, nous avons réussit à calculer des séries de $v_i^n$ très précis. Nous allons pouvoir entrainer des réseaux de neurones.  \n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"O-N8krH5qP8C"},"source":["### Baseline\n","\n","Un réseau de neurone $G_\\theta(w_{i-1},w_i,w_{i+1})$ qui est cencé directement reproduire $v_i$. On ne le structure pas du tout. La loss associée sera diretement\n","$$\n","\\mathtt{Loss}^G_i = G(w_{i-1},w_i,w_{i+1}) - v_i\n","$$\n","puis\n","$$\n","\\mathtt{Loss}^G= \\sum_i \\mathtt{Loss}^G_i\n","$$\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lL3wY5dEqwHT"},"source":["### Le réseau différence\n","\n","On se donne un réseau $F_\\theta(w_i,w_{i+1})$. On prend comme première loss:\n","$$\n","\\mathtt{lossDiff}_i = \\frac{F_\\theta(w_i,w_{i+1})- F_\\theta(w_{i-1},w_{i})}{\\delta_x}  - v_i\n","$$\n","puis\n","$$\n","\\mathtt{lossDiff} = \\sum_i \\mathtt{lossDiff}_i\n","$$\n","Mais avec  cette seule loss, l'apprentissage ne pourra pas converger: en ajoutant une constante à $F_\\theta$ on ne change pas la loss.  \n","\n","On peut alors ajouter un terme de pénalisation par exemple:\n","$$\n","\\mathtt{loss}_{\\alpha} = \\mathtt{lossDiff}+ \\alpha \\sum w^2\n","$$\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gtdaaa5crhgj"},"source":["### Une seconde contraine\n","\n","Mais on peut aussi penser à une seconde contrainte:\n","\n","On aimerait aussi que notre réseau satisface cette contrainte: \n","$$\\tag{C2}\n","F_\\theta(w_i,w_i) \\approx  F(w_i)\n","$$\n","Cette contrainte est naturelle quand on se souvient que\n","$$\n","F_\\theta(w(x_i),w(x_{i+1})) \\text{ doit approcher } F\\circ w (\\frac {x_i+x_{i+1}}2)\n","$$\n","Quand le pas du maillage tend vers 0, on obtient cette seconde contrainte. Ainsi:\n","\n","$$\n","\\mathtt{loss}^{C2}=\\mathtt{lossDiff}  +  \\sum_i F_\\theta(w_i,w_i)-F(w_i)\n","$$\n","Remarquons que cette seconde condition ne lève par complètement l'intermination: en ajoutant à $F_\\theta$ une fonction $H(w_i,w_{i+1})$ qui s'annule sur la diagonale, la loss ne change pas. Il faut surement un peu pénaliser aussi. \n"]},{"cell_type":"markdown","metadata":{"id":"XNYo07FnE8zW"},"source":["### Réseau addifif\n","\n","C'est le réseau le plus structuré. C'est un peu l'idée des resNet: le réseau de neurone ajoute un terme à une quantité déjà bonne: \n","\n","On  considére un réseau de neurone $A_\\theta$ puis\n","$$\n","F^A_\\theta(w_i,w_{i+1}) = \\frac{F(w_i)+F(w_{i+1})}{ 2}  + A_\\theta(w_i,w_{i+1})(w_{i+1}-w_i)\n","$$\n","Remarquons que le solution $(C2)$ est automatiquement satisfaite par ce réseau. \n","\n","Ensuite on fait comme d'habitude: \n","$$\n","\\mathtt{lossDiff}^A_i =  F^A_\\theta(w_i,w_{i+1}) -F^A_\\theta(w_{i-1},w_{i}) - v_i  \n","$$\n","puis on pénalise: \n","$$\n","\\mathtt{loss}^A_{\\alpha} = \\mathtt{lossDiff}^A+ \\alpha \\sum w^2\n","$$\n"]},{"cell_type":"markdown","metadata":{"id":"WJMV7su0H7AI"},"source":["### Plus de points pour interpoler ? \n","\n","Pour faire une interpolation précise il faut souvent considérer les voisins plus lointains. On pourait donc prendre\n","$$ \n","F_\\theta(w_{i-1},w_i,w_{i+1},w_{i+2}) \\approx F( w_{i+\\frac 12})\n","$$\n","Ce qui conduirait à une différence\n","$$\n","F\\!F_\\theta (w_{i-2},w_{i-1},w_i,w_{i+1},w_{i+2}) \\approx v_i\n","$$\n","Et comme baseline un simple réseau non structuré\n","$$\n","G_\\theta (w_{i-2},w_{i-1},w_i,w_{i+1},w_{i+2}) \\approx v_i\n","$$\n","Ou en poussant encore plus loin de bouchon: on pourrait tester une estimation globale en espace de type Vnet. \n","$$\n","Vnet_\\theta(w_.) \\approx v_.\n","$$\n","sachant que le Vnet est une réseau de convolution, donc il peut glisser sur des données de taille arbitraire. Il produit simplement plusieurs output d'un coup. "]},{"cell_type":"markdown","metadata":{"id":"X54WC7V6cXp3"},"source":["## Notre problème en particulier"]},{"cell_type":"markdown","metadata":{"id":"p1xB3-niXhPT"},"source":["### l'EDP"]},{"cell_type":"markdown","metadata":{"id":"QPDBQ5HP6yqz"},"source":["\n","* $\\rho(x,t)$ : une densité de gaz neutre. \n","* $E$ : Energie totale du gaz\n","* $V$ : vitesse moyenne du gaz\n","\n","Les inconnues sont \n","* $\\rho$\n","* $V$ (ou $\\rho V$)\n","* $p$ (ou $E$).\n","\n","Le système d'équations est:\n","$$\n","\\partial_t \\rho + \\partial_x (\\rho V) = 0 \n","$$\n","$$\n","\\partial_t \\rho V + \\partial_x (\\rho V^2 +p)   =0\n","$$\n","$$\n","\\partial_t E +\\partial_x (EV + pV)  =0\n","$$\n","$p$ et $E$ sont équivalente par la formule suivante:\n","$$\n","E = \\frac 12 \\rho V^2+ \\frac 1{\\gamma - 1 } p\n","$$\n","\n","$\\gamma$ est un paramètre physique. Entre $1$ et $3$. (pour l'instant fixe). \n","\n"]},{"cell_type":"markdown","source":["***Attention:*** Par rapport au doc de référence, chez nous \n","$E$ correspond à $\\rho E$ chez eux."],"metadata":{"id":"6R9xhbZIcnCH"}},{"cell_type":"markdown","metadata":{"id":"rdq6Yg5Hcers"},"source":["### Vectorisation"]},{"cell_type":"markdown","metadata":{"id":"Dl44wDotcltT"},"source":["On note\n","$$\n","w(x,t)=[\\rho(x,t),\\rho V(x,t), E(x,t)]\n","$$\n","$$\n","v(x,t) = \\partial_t w(x,t)\n","$$\n","On considère ensuite:\n","$$\n","F( w ) = -[\\rho V, \\rho V^2+p, EV+p V]\n","$$\n","(La fonction $F$ peut facilement être explicitée).  \n","\n","l'EDP se réécrit alors: \n","$$\n","v =  \\partial_x F( w)\n","$$\n","et on rentre dans le cadre général décrit précédemment. \n","\n","\n","\n","***Remarque:*** En pratique, pour nourir le machine learning on utiliser un vecteur \"augmenté\" (data augmentation)\n","$$\n","\\bar w(x)=[\\rho(x),\\rho V(x), E(x), V(x), p(x),...]\n","$$"]},{"cell_type":"markdown","metadata":{"id":"JF3_BZi2WVYC"},"source":["## Intervention du temps\n","\n","Le supervisé est la pour la consistance\n","\n","Le renforcement est là pour la stabilité, puisqu'il regarde tous les temps. \n","\n","Côté multi-agent. \n","\n","    s'r= env(s,a) \n","\n","ici : plein de petit \n","\n","    s = w_l,w_r\n","    a = F_theta #1 seule politique\n","\n","    S=s_1,...,s_100\n","    A=a_1,...,a_100\n","\n","    S',r=env(S,A)\n","\n","\n","Problème complétement coopératif: la même politique pour chaque agent. L'action est \"locale\". \n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VhbAcmt11ry1"},"source":["### Moyen d'assurer la stabilité\n","\n","...\n","\n","\n","Une fonction de entropie  $H(w_i)$. \n","\n","tu construit une second réseau ne neurone\n","\n","***Théoreme:*** Si il existe un $Q_\\theta$ vérifiant ceci\n","$$\n","[H(w_i^{n+1})-H(w_i^{n})] / \\delta_i  + [Q_\\theta(w_i^n ,w_{i+1}^n )- Q_\\theta(w_{i-1}^n ,w_{i}^n )] / \\delta_x \\leq 0\n","$$\n","Alors c'est stable. \n","\n","\n","$$\n","H(w_i^{n+1}) = ....\n","$$\n","\n","Et le $w^{n+1}$ c'est celui obtenu avec $F_\\theta$. Tu calcul un \n","$$\n","H(w^*)= \n","$$\n","pour que l'inégalité soit accepté et il faut que \n","\n","On construit les 2 réseaux."]},{"cell_type":"markdown","metadata":{"id":"wwFSYveXZbI9"},"source":["### La solution RNN\n","\n","A partir de maintenant pour simplifier, nous allons parler uniquement de $F\\! F_\\theta$ sachant de la meilleurs technique (sans doute) c'est de l'exprimer comme une différence de 2 réseaux de neurones. \n","\n","Et nous simplifierons l'équation locale\n","$$\n","v_i = F\\! F_\\theta(w_{i-1},w_i,w_{i+1}) \n","$$\n","Par la notation  \"globale\" en espace (mais ce n'est qu'une notation, nous pensons toujours que $F\\! F$  agit semi-localement\n","$$\n","v = F\\! F_\\theta(w) \n","$$\n","... A suivre\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hyf4IIHBcjDU"},"source":["### Exagérer les problèmes pour mieux les minimser. \n","\n","Il faut que les  erreurs sur la sortie de $F_\\theta$ se ressentent fortement sur la loss.\n","\n","\n","\n"]}]}