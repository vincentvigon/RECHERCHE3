{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KGCNN.ipynb","provenance":[],"authorship_tag":"ABX9TyO5S7YvtI/AUpM7WxgFQMP3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WVDbVNmpf5HH"},"source":["[article, ici](https://arxiv.org/pdf/2103.04318.pdf)\n","\n","[github, ici](https://github.com/aimat-lab/gcnn_keras)\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGqae1Hmf_eP","executionInfo":{"status":"ok","timestamp":1620133894804,"user_tz":-120,"elapsed":5365,"user":{"displayName":"vincent vigon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64","userId":"09456169185020192907"}},"outputId":"9666ed2e-15e6-45ef-cf31-185bbdc986ae"},"source":["pip install kgcnn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting kgcnn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/07bb956beae12ef443a7c984f31236869fb890975459abd268d060088980/kgcnn-0.1.1-py3-none-any.whl (85kB)\n","\r\u001b[K     |███▉                            | 10kB 12.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 51kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.7MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from kgcnn) (1.1.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from kgcnn) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kgcnn) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kgcnn) (2.23.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kgcnn) (1.4.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from kgcnn) (0.22.2.post1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->kgcnn) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->kgcnn) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kgcnn) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kgcnn) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->kgcnn) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kgcnn) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->kgcnn) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->kgcnn) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kgcnn) (2.10)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->kgcnn) (1.0.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->kgcnn) (1.15.0)\n","Installing collected packages: kgcnn\n","Successfully installed kgcnn-0.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMcJThIhjIJE","executionInfo":{"status":"ok","timestamp":1620134632370,"user_tz":-120,"elapsed":3489,"user":{"displayName":"vincent vigon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64","userId":"09456169185020192907"}},"outputId":"9d2d6ded-a838-4c17-8ef8-70350c19b1d5"},"source":["import time\n","\n","# mpl.use('Agg')\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","from kgcnn.data.mutagen.mutag import mutag_graph\n","from kgcnn.literature.Unet import make_unet as make_unet\n","from kgcnn.utils.adj import add_self_loops_to_edge_indices\n","from kgcnn.utils.data import ragged_tensor_from_nested_numpy\n","from kgcnn.utils.learning import lr_lin_reduction"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Keras utils: Register custom activation:  {'leaky_softplus': <function leaky_softplus at 0x7f90e01b07a0>, 'shifted_softplus': <function shifted_softplus at 0x7f90e01b0440>, 'softplus2': <function softplus2 at 0x7f90e01b03b0>}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Pn4E7hpDgS40","executionInfo":{"status":"ok","timestamp":1620134928501,"user_tz":-120,"elapsed":239532,"user":{"displayName":"vincent vigon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64","userId":"09456169185020192907"}},"outputId":"6f211429-4e44-4d03-8ed5-82923d392f29"},"source":["# Download and prepare dataset\n","labels, nodes, edge_indices, edges = mutag_graph()\n","labels[labels < 0] = 0\n","labels = np.expand_dims(labels, axis=-1)\n","graph_state = np.array([len(x) for x in nodes])\n","edge_indices = [add_self_loops_to_edge_indices(x) for x in edge_indices]\n","edges = [np.ones_like(x, dtype=np.float)[:, 0:1] for x in edge_indices]\n","\n","# Train Test split\n","labels_train, labels_test, nodes_train, nodes_test, edges_train, edges_test, edge_indices_train, edge_indices_test, graph_state_train, graph_state_test = train_test_split(\n","    labels, nodes, edges, edge_indices, graph_state, test_size=0.10, random_state=42)\n","del labels, nodes, edges, edge_indices, graph_state  # Free memory after split, if possible\n","\n","# Convert to tf.RaggedTensor or tf.tensor\n","# a copy of the data is generated by ragged_tensor_from_nested_numpy()\n","nodes_train, edges_train, edge_indices_train, graph_state_train = ragged_tensor_from_nested_numpy(\n","    nodes_train), ragged_tensor_from_nested_numpy(edges_train), ragged_tensor_from_nested_numpy(\n","    edge_indices_train), tf.constant(graph_state_train)\n","\n","nodes_test, edges_test, edge_indices_test, graph_state_test = ragged_tensor_from_nested_numpy(\n","    nodes_test), ragged_tensor_from_nested_numpy(edges_test), ragged_tensor_from_nested_numpy(\n","    edge_indices_test), tf.constant(graph_state_test)\n","\n","# Define input and output data\n","xtrain = nodes_train, edges_train, edge_indices_train\n","xtest = nodes_test, edges_test, edge_indices_test\n","ytrain = labels_train\n","ytest = labels_test\n","\n","model = make_unet(\n","    input_node_shape=[None],\n","    input_edge_shape=[None, 1],\n","    input_embedd={\"input_node_vocab\": 60,\n","                  \"input_node_embedd\": 128},\n","    # Output\n","    output_embedd={\"output_mode\": 'graph', \"output_type\": 'padded'},\n","    output_mlp={\"use_bias\": [True, False], \"units\": [25, 1],\n","                \"activation\": ['relu', 'sigmoid'],\n","                },\n","    # Model specific\n","    hidden_dim=128,\n","    depth=4,\n","    k=0.3,\n","    score_initializer='ones',\n","    use_bias=True,\n","    activation='relu',\n","    is_sorted=False,\n","    has_unconnected=True,\n","    use_reconnect=True\n",")\n","\n","# Define learning rate\n","learning_rate_start = 1e-4\n","learning_rate_stop = 1e-5\n","epo = 500\n","epomin = 400\n","epostep = 2\n","\n","# Compile model with optimizer\n","optimizer = tf.keras.optimizers.Adam(lr=learning_rate_start)\n","cbks = tf.keras.callbacks.LearningRateScheduler(lr_lin_reduction(learning_rate_start, learning_rate_stop, epomin, epo))\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizer,\n","              metrics=['accuracy'])\n","print(model.summary())\n","\n","start = time.process_time()\n","hist = model.fit(xtrain, ytrain,\n","                 epochs=epo,\n","                 batch_size=32,\n","                 callbacks=[cbks],\n","                 validation_freq=epostep,\n","                 validation_data=(xtest, ytest),\n","                 verbose=2\n","                 )\n","stop = time.process_time()\n","print(\"Print Time for taining: \", stop - start)\n","\n","trainlossall = np.array(hist.history['accuracy'])\n","testlossall = np.array(hist.history['val_accuracy'])\n","\n","mae_valid = testlossall[-1]\n","\n","# Plot loss vs epochs\n","plt.figure()\n","plt.plot(np.arange(trainlossall.shape[0]), trainlossall, label='Training ACC', c='blue')\n","plt.plot(np.arange(epostep, epo + epostep, epostep), testlossall, label='Test ACC', c='red')\n","plt.scatter([trainlossall.shape[0]], [mae_valid], label=\"{0:0.4f} \".format(mae_valid), c='red')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.title('Interaction Network Loss')\n","plt.legend(loc='upper right', fontsize='x-large')\n","plt.savefig('unet_loss.png')\n","plt.show()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Setup local data folder for kgcnn at:  /root/.kgcnn\n","Database path: /root/.kgcnn/data/mutagen\n","Downloading dataset...done\n","Read Zip File ... done\n","Extracting Zip folder...done\n","Making graph ...Datainfo: Mol index which has unconnected [] with [] in total 0\n","done\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","node_input (InputLayer)         [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","node_embedding (Embedding)      (None, None, 128)    7680        node_input[0][0]                 \n","__________________________________________________________________________________________________\n","dense_ragged (DenseRagged)      (None, None, 128)    16512       node_embedding[0][0]             \n","__________________________________________________________________________________________________\n","edge_input (InputLayer)         [(None, None, 1)]    0                                            \n","__________________________________________________________________________________________________\n","edge_index_input (InputLayer)   [(None, None, 2)]    0                                            \n","__________________________________________________________________________________________________\n","cast_ragged_to_disjoint (CastRa [(None, 128), (None, 0           dense_ragged[0][0]               \n","                                                                 edge_input[0][0]                 \n","                                                                 edge_index_input[0][0]           \n","__________________________________________________________________________________________________\n","gather_nodes_outgoing (GatherNo (None, 128)          0           cast_ragged_to_disjoint[0][0]    \n","                                                                 cast_ragged_to_disjoint[0][1]    \n","                                                                 cast_ragged_to_disjoint[0][4]    \n","                                                                 cast_ragged_to_disjoint[0][3]    \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 128)          16512       gather_nodes_outgoing[0][0]      \n","__________________________________________________________________________________________________\n","pooling_local_edges (PoolingLoc (None, 128)          0           cast_ragged_to_disjoint[0][0]    \n","                                                                 cast_ragged_to_disjoint[0][1]    \n","                                                                 dense[0][0]                      \n","                                                                 cast_ragged_to_disjoint[0][3]    \n","                                                                 cast_ragged_to_disjoint[0][4]    \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, 128)          0           pooling_local_edges[0][0]        \n","__________________________________________________________________________________________________\n","adjacency_power (AdjacencyPower [(None, 2), (None, 1 0           cast_ragged_to_disjoint[0][4]    \n","                                                                 cast_ragged_to_disjoint[0][2]    \n","                                                                 cast_ragged_to_disjoint[0][3]    \n","                                                                 cast_ragged_to_disjoint[0][1]    \n","__________________________________________________________________________________________________\n","pooling_top_k (PoolingTopK)     ([(None, 128), (None 128         activation[0][0]                 \n","                                                                 cast_ragged_to_disjoint[0][1]    \n","                                                                 adjacency_power[0][1]            \n","                                                                 adjacency_power[0][2]            \n","                                                                 adjacency_power[0][0]            \n","__________________________________________________________________________________________________\n","gather_nodes_outgoing_1 (Gather (None, 128)          0           pooling_top_k[0][0]              \n","                                                                 pooling_top_k[0][1]              \n","                                                                 pooling_top_k[0][4]              \n","                                                                 pooling_top_k[0][3]              \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 128)          16512       gather_nodes_outgoing_1[0][0]    \n","__________________________________________________________________________________________________\n","pooling_local_edges_1 (PoolingL (None, 128)          0           pooling_top_k[0][0]              \n","                                                                 pooling_top_k[0][1]              \n","                                                                 dense_1[0][0]                    \n","                                                                 pooling_top_k[0][3]              \n","                                                                 pooling_top_k[0][4]              \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, 128)          0           pooling_local_edges_1[0][0]      \n","__________________________________________________________________________________________________\n","adjacency_power_1 (AdjacencyPow [(None, 2), (None, 1 0           pooling_top_k[0][4]              \n","                                                                 pooling_top_k[0][2]              \n","                                                                 pooling_top_k[0][3]              \n","                                                                 pooling_top_k[0][1]              \n","__________________________________________________________________________________________________\n","pooling_top_k_1 (PoolingTopK)   ([(None, 128), (None 128         activation_1[0][0]               \n","                                                                 pooling_top_k[0][1]              \n","                                                                 adjacency_power_1[0][1]          \n","                                                                 adjacency_power_1[0][2]          \n","                                                                 adjacency_power_1[0][0]          \n","__________________________________________________________________________________________________\n","gather_nodes_outgoing_2 (Gather (None, 128)          0           pooling_top_k_1[0][0]            \n","                                                                 pooling_top_k_1[0][1]            \n","                                                                 pooling_top_k_1[0][4]            \n","                                                                 pooling_top_k_1[0][3]            \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 128)          16512       gather_nodes_outgoing_2[0][0]    \n","__________________________________________________________________________________________________\n","pooling_local_edges_2 (PoolingL (None, 128)          0           pooling_top_k_1[0][0]            \n","                                                                 pooling_top_k_1[0][1]            \n","                                                                 dense_2[0][0]                    \n","                                                                 pooling_top_k_1[0][3]            \n","                                                                 pooling_top_k_1[0][4]            \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, 128)          0           pooling_local_edges_2[0][0]      \n","__________________________________________________________________________________________________\n","adjacency_power_2 (AdjacencyPow [(None, 2), (None, 1 0           pooling_top_k_1[0][4]            \n","                                                                 pooling_top_k_1[0][2]            \n","                                                                 pooling_top_k_1[0][3]            \n","                                                                 pooling_top_k_1[0][1]            \n","__________________________________________________________________________________________________\n","pooling_top_k_2 (PoolingTopK)   ([(None, 128), (None 128         activation_2[0][0]               \n","                                                                 pooling_top_k_1[0][1]            \n","                                                                 adjacency_power_2[0][1]          \n","                                                                 adjacency_power_2[0][2]          \n","                                                                 adjacency_power_2[0][0]          \n","__________________________________________________________________________________________________\n","gather_nodes_outgoing_3 (Gather (None, 128)          0           pooling_top_k_2[0][0]            \n","                                                                 pooling_top_k_2[0][1]            \n","                                                                 pooling_top_k_2[0][4]            \n","                                                                 pooling_top_k_2[0][3]            \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 128)          16512       gather_nodes_outgoing_3[0][0]    \n","__________________________________________________________________________________________________\n","pooling_local_edges_3 (PoolingL (None, 128)          0           pooling_top_k_2[0][0]            \n","                                                                 pooling_top_k_2[0][1]            \n","                                                                 dense_3[0][0]                    \n","                                                                 pooling_top_k_2[0][3]            \n","                                                                 pooling_top_k_2[0][4]            \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 128)          0           pooling_local_edges_3[0][0]      \n","__________________________________________________________________________________________________\n","adjacency_power_3 (AdjacencyPow [(None, 2), (None, 1 0           pooling_top_k_2[0][4]            \n","                                                                 pooling_top_k_2[0][2]            \n","                                                                 pooling_top_k_2[0][3]            \n","                                                                 pooling_top_k_2[0][1]            \n","__________________________________________________________________________________________________\n","pooling_top_k_3 (PoolingTopK)   ([(None, 128), (None 128         activation_3[0][0]               \n","                                                                 pooling_top_k_2[0][1]            \n","                                                                 adjacency_power_3[0][1]          \n","                                                                 adjacency_power_3[0][2]          \n","                                                                 adjacency_power_3[0][0]          \n","__________________________________________________________________________________________________\n","un_pooling_top_k (UnPoolingTopK [(None, None), (None 0           pooling_top_k_2[0][0]            \n","                                                                 pooling_top_k_2[0][1]            \n","                                                                 pooling_top_k_2[0][2]            \n","                                                                 pooling_top_k_2[0][3]            \n","                                                                 pooling_top_k_2[0][4]            \n","                                                                 pooling_top_k_3[0][5]            \n","                                                                 pooling_top_k_3[0][6]            \n","                                                                 pooling_top_k_3[0][0]            \n","                                                                 pooling_top_k_3[0][1]            \n","                                                                 pooling_top_k_3[0][2]            \n","                                                                 pooling_top_k_3[0][3]            \n","                                                                 pooling_top_k_3[0][4]            \n","__________________________________________________________________________________________________\n","add (Add)                       (None, 128)          0           un_pooling_top_k[0][0]           \n","                                                                 pooling_top_k_2[0][0]            \n","__________________________________________________________________________________________________\n","gather_nodes_outgoing_4 (Gather (None, 128)          0           add[0][0]                        \n","                                                                 un_pooling_top_k[0][1]           \n","                                                                 un_pooling_top_k[0][4]           \n","                                                                 un_pooling_top_k[0][3]           \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 128)          16512       gather_nodes_outgoing_4[0][0]    \n","__________________________________________________________________________________________________\n","pooling_local_edges_4 (PoolingL (None, 128)          0           add[0][0]                        \n","                                                                 un_pooling_top_k[0][1]           \n","                                                                 dense_4[0][0]                    \n","                                                                 un_pooling_top_k[0][3]           \n","                                                                 un_pooling_top_k[0][4]           \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 128)          0           pooling_local_edges_4[0][0]      \n","__________________________________________________________________________________________________\n","un_pooling_top_k_1 (UnPoolingTo [(None, None), (None 0           pooling_top_k_1[0][0]            \n","                                                                 pooling_top_k_1[0][1]            \n","                                                                 pooling_top_k_1[0][2]            \n","                                                                 pooling_top_k_1[0][3]            \n","                                                                 pooling_top_k_1[0][4]            \n","                                                                 pooling_top_k_2[0][5]            \n","                                                                 pooling_top_k_2[0][6]            \n","                                                                 activation_4[0][0]               \n","                                                                 un_pooling_top_k[0][1]           \n","                                                                 un_pooling_top_k[0][2]           \n","                                                                 un_pooling_top_k[0][3]           \n","                                                                 un_pooling_top_k[0][4]           \n","__________________________________________________________________________________________________\n","add_1 (Add)                     (None, 128)          0           un_pooling_top_k_1[0][0]         \n","                                                                 pooling_top_k_1[0][0]            \n","__________________________________________________________________________________________________\n","gather_nodes_outgoing_5 (Gather (None, 128)          0           add_1[0][0]                      \n","                                                                 un_pooling_top_k_1[0][1]         \n","                                                                 un_pooling_top_k_1[0][4]         \n","                                                                 un_pooling_top_k_1[0][3]         \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 128)          16512       gather_nodes_outgoing_5[0][0]    \n","__________________________________________________________________________________________________\n","pooling_local_edges_5 (PoolingL (None, 128)          0           add_1[0][0]                      \n","                                                                 un_pooling_top_k_1[0][1]         \n","                                                                 dense_5[0][0]                    \n","                                                                 un_pooling_top_k_1[0][3]         \n","                                                                 un_pooling_top_k_1[0][4]         \n","__________________________________________________________________________________________________\n","activation_5 (Activation)       (None, 128)          0           pooling_local_edges_5[0][0]      \n","__________________________________________________________________________________________________\n","un_pooling_top_k_2 (UnPoolingTo [(None, None), (None 0           pooling_top_k[0][0]              \n","                                                                 pooling_top_k[0][1]              \n","                                                                 pooling_top_k[0][2]              \n","                                                                 pooling_top_k[0][3]              \n","                                                                 pooling_top_k[0][4]              \n","                                                                 pooling_top_k_1[0][5]            \n","                                                                 pooling_top_k_1[0][6]            \n","                                                                 activation_5[0][0]               \n","                                                                 un_pooling_top_k_1[0][1]         \n","                                                                 un_pooling_top_k_1[0][2]         \n","                                                                 un_pooling_top_k_1[0][3]         \n","                                                                 un_pooling_top_k_1[0][4]         \n","__________________________________________________________________________________________________\n","add_2 (Add)                     (None, 128)          0           un_pooling_top_k_2[0][0]         \n","                                                                 pooling_top_k[0][0]              \n","__________________________________________________________________________________________________\n","gather_nodes_outgoing_6 (Gather (None, 128)          0           add_2[0][0]                      \n","                                                                 un_pooling_top_k_2[0][1]         \n","                                                                 un_pooling_top_k_2[0][4]         \n","                                                                 un_pooling_top_k_2[0][3]         \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 128)          16512       gather_nodes_outgoing_6[0][0]    \n","__________________________________________________________________________________________________\n","pooling_local_edges_6 (PoolingL (None, 128)          0           add_2[0][0]                      \n","                                                                 un_pooling_top_k_2[0][1]         \n","                                                                 dense_6[0][0]                    \n","                                                                 un_pooling_top_k_2[0][3]         \n","                                                                 un_pooling_top_k_2[0][4]         \n","__________________________________________________________________________________________________\n","activation_6 (Activation)       (None, 128)          0           pooling_local_edges_6[0][0]      \n","__________________________________________________________________________________________________\n","un_pooling_top_k_3 (UnPoolingTo [(None, None), (None 0           cast_ragged_to_disjoint[0][0]    \n","                                                                 cast_ragged_to_disjoint[0][1]    \n","                                                                 cast_ragged_to_disjoint[0][2]    \n","                                                                 cast_ragged_to_disjoint[0][3]    \n","                                                                 cast_ragged_to_disjoint[0][4]    \n","                                                                 pooling_top_k[0][5]              \n","                                                                 pooling_top_k[0][6]              \n","                                                                 activation_6[0][0]               \n","                                                                 un_pooling_top_k_2[0][1]         \n","                                                                 un_pooling_top_k_2[0][2]         \n","                                                                 un_pooling_top_k_2[0][3]         \n","                                                                 un_pooling_top_k_2[0][4]         \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 128)          0           un_pooling_top_k_3[0][0]         \n","                                                                 cast_ragged_to_disjoint[0][0]    \n","__________________________________________________________________________________________________\n","gather_nodes_outgoing_7 (Gather (None, 128)          0           add_3[0][0]                      \n","                                                                 un_pooling_top_k_3[0][1]         \n","                                                                 un_pooling_top_k_3[0][4]         \n","                                                                 un_pooling_top_k_3[0][3]         \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 128)          16512       gather_nodes_outgoing_7[0][0]    \n","__________________________________________________________________________________________________\n","pooling_local_edges_7 (PoolingL (None, 128)          0           add_3[0][0]                      \n","                                                                 un_pooling_top_k_3[0][1]         \n","                                                                 dense_7[0][0]                    \n","                                                                 un_pooling_top_k_3[0][3]         \n","                                                                 un_pooling_top_k_3[0][4]         \n","__________________________________________________________________________________________________\n","activation_7 (Activation)       (None, 128)          0           pooling_local_edges_7[0][0]      \n","__________________________________________________________________________________________________\n","pooling_nodes (PoolingNodes)    (None, 128)          0           activation_7[0][0]               \n","                                                                 un_pooling_top_k_3[0][1]         \n","__________________________________________________________________________________________________\n","mlp (MLP)                       (None, 1)            3250        pooling_nodes[0][0]              \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 1)            0           mlp[0][0]                        \n","==================================================================================================\n","Total params: 160,050\n","Trainable params: 160,050\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n","Epoch 1/500\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges_7/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges_7/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gather_nodes_outgoing_7/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/gather_nodes_outgoing_7/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gather_nodes_outgoing_7/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges_6/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges_6/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gather_nodes_outgoing_6/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/gather_nodes_outgoing_6/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gather_nodes_outgoing_6/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges_5/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges_5/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges_5/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gather_nodes_outgoing_5/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/gather_nodes_outgoing_5/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gather_nodes_outgoing_5/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges_4/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges_4/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges_4/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gather_nodes_outgoing_4/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/gather_nodes_outgoing_4/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gather_nodes_outgoing_4/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_top_k_3/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_top_k_3/Reshape_3:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_top_k_3/Cast_1:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_top_k_3/Reshape_2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_top_k_3/Reshape_1:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_top_k_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges_3/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges_3/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gather_nodes_outgoing_3/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/gather_nodes_outgoing_3/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gather_nodes_outgoing_3/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_top_k_2/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_top_k_2/Reshape_3:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_top_k_2/Cast_1:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_top_k_2/Reshape_2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_top_k_2/Reshape_1:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_top_k_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges_2/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges_2/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gather_nodes_outgoing_2/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/gather_nodes_outgoing_2/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gather_nodes_outgoing_2/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_top_k_1/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_top_k_1/Reshape_3:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_top_k_1/Cast_1:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_top_k_1/Reshape_2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_top_k_1/Reshape_1:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_top_k_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges_1/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges_1/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gather_nodes_outgoing_1/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/gather_nodes_outgoing_1/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gather_nodes_outgoing_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_top_k/Reshape_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_top_k/Reshape_3:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_top_k/Cast_1:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_top_k/Reshape_2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_top_k/Reshape_1:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_top_k/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/pooling_local_edges/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/pooling_local_edges/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/pooling_local_edges/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/gather_nodes_outgoing/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/model/gather_nodes_outgoing/Reshape:0\", shape=(None, 128), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/gather_nodes_outgoing/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"shape. This may consume a large amount of memory.\" % value)\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 - 12s - loss: 0.6929 - accuracy: 0.5266\n","Epoch 2/500\n","6/6 - 5s - loss: 0.6872 - accuracy: 0.6686 - val_loss: 0.6855 - val_accuracy: 0.6316\n","Epoch 3/500\n","6/6 - 0s - loss: 0.6820 - accuracy: 0.6686\n","Epoch 4/500\n","6/6 - 1s - loss: 0.6775 - accuracy: 0.6686 - val_loss: 0.6775 - val_accuracy: 0.6316\n","Epoch 5/500\n","6/6 - 0s - loss: 0.6730 - accuracy: 0.6686\n","Epoch 6/500\n","6/6 - 1s - loss: 0.6681 - accuracy: 0.6686 - val_loss: 0.6698 - val_accuracy: 0.6316\n","Epoch 7/500\n","6/6 - 0s - loss: 0.6636 - accuracy: 0.6686\n","Epoch 8/500\n","6/6 - 1s - loss: 0.6576 - accuracy: 0.6686 - val_loss: 0.6617 - val_accuracy: 0.6316\n","Epoch 9/500\n","6/6 - 0s - loss: 0.6533 - accuracy: 0.6686\n","Epoch 10/500\n","6/6 - 1s - loss: 0.6474 - accuracy: 0.6686 - val_loss: 0.6540 - val_accuracy: 0.6316\n","Epoch 11/500\n","6/6 - 0s - loss: 0.6433 - accuracy: 0.6686\n","Epoch 12/500\n","6/6 - 1s - loss: 0.6384 - accuracy: 0.6686 - val_loss: 0.6486 - val_accuracy: 0.6316\n","Epoch 13/500\n","6/6 - 1s - loss: 0.6350 - accuracy: 0.6686\n","Epoch 14/500\n","6/6 - 1s - loss: 0.6316 - accuracy: 0.6686 - val_loss: 0.6444 - val_accuracy: 0.6316\n","Epoch 15/500\n","6/6 - 0s - loss: 0.6288 - accuracy: 0.6686\n","Epoch 16/500\n","6/6 - 1s - loss: 0.6276 - accuracy: 0.6686 - val_loss: 0.6430 - val_accuracy: 0.6316\n","Epoch 17/500\n","6/6 - 0s - loss: 0.6260 - accuracy: 0.6686\n","Epoch 18/500\n","6/6 - 1s - loss: 0.6250 - accuracy: 0.6686 - val_loss: 0.6428 - val_accuracy: 0.6316\n","Epoch 19/500\n","6/6 - 0s - loss: 0.6247 - accuracy: 0.6686\n","Epoch 20/500\n","6/6 - 1s - loss: 0.6239 - accuracy: 0.6686 - val_loss: 0.6405 - val_accuracy: 0.6316\n","Epoch 21/500\n","6/6 - 0s - loss: 0.6230 - accuracy: 0.6686\n","Epoch 22/500\n","6/6 - 1s - loss: 0.6225 - accuracy: 0.6686 - val_loss: 0.6383 - val_accuracy: 0.6316\n","Epoch 23/500\n","6/6 - 0s - loss: 0.6221 - accuracy: 0.6686\n","Epoch 24/500\n","6/6 - 1s - loss: 0.6213 - accuracy: 0.6686 - val_loss: 0.6388 - val_accuracy: 0.6316\n","Epoch 25/500\n","6/6 - 1s - loss: 0.6207 - accuracy: 0.6686\n","Epoch 26/500\n","6/6 - 1s - loss: 0.6203 - accuracy: 0.6686 - val_loss: 0.6386 - val_accuracy: 0.6316\n","Epoch 27/500\n","6/6 - 1s - loss: 0.6204 - accuracy: 0.6686\n","Epoch 28/500\n","6/6 - 1s - loss: 0.6196 - accuracy: 0.6686 - val_loss: 0.6366 - val_accuracy: 0.6316\n","Epoch 29/500\n","6/6 - 0s - loss: 0.6187 - accuracy: 0.6686\n","Epoch 30/500\n","6/6 - 1s - loss: 0.6181 - accuracy: 0.6686 - val_loss: 0.6339 - val_accuracy: 0.6316\n","Epoch 31/500\n","6/6 - 0s - loss: 0.6179 - accuracy: 0.6686\n","Epoch 32/500\n","6/6 - 1s - loss: 0.6173 - accuracy: 0.6686 - val_loss: 0.6325 - val_accuracy: 0.6316\n","Epoch 33/500\n","6/6 - 0s - loss: 0.6170 - accuracy: 0.6686\n","Epoch 34/500\n","6/6 - 1s - loss: 0.6163 - accuracy: 0.6686 - val_loss: 0.6307 - val_accuracy: 0.6316\n","Epoch 35/500\n","6/6 - 1s - loss: 0.6154 - accuracy: 0.6686\n","Epoch 36/500\n","6/6 - 1s - loss: 0.6151 - accuracy: 0.6686 - val_loss: 0.6307 - val_accuracy: 0.6316\n","Epoch 37/500\n","6/6 - 1s - loss: 0.6153 - accuracy: 0.6686\n","Epoch 38/500\n","6/6 - 1s - loss: 0.6143 - accuracy: 0.6686 - val_loss: 0.6268 - val_accuracy: 0.6316\n","Epoch 39/500\n","6/6 - 0s - loss: 0.6140 - accuracy: 0.6686\n","Epoch 40/500\n","6/6 - 1s - loss: 0.6129 - accuracy: 0.6686 - val_loss: 0.6246 - val_accuracy: 0.6316\n","Epoch 41/500\n","6/6 - 0s - loss: 0.6122 - accuracy: 0.6686\n","Epoch 42/500\n","6/6 - 1s - loss: 0.6119 - accuracy: 0.6686 - val_loss: 0.6237 - val_accuracy: 0.6316\n","Epoch 43/500\n","6/6 - 0s - loss: 0.6111 - accuracy: 0.6686\n","Epoch 44/500\n","6/6 - 1s - loss: 0.6104 - accuracy: 0.6686 - val_loss: 0.6199 - val_accuracy: 0.6316\n","Epoch 45/500\n","6/6 - 0s - loss: 0.6095 - accuracy: 0.6686\n","Epoch 46/500\n","6/6 - 1s - loss: 0.6090 - accuracy: 0.6686 - val_loss: 0.6174 - val_accuracy: 0.6316\n","Epoch 47/500\n","6/6 - 0s - loss: 0.6081 - accuracy: 0.6686\n","Epoch 48/500\n","6/6 - 1s - loss: 0.6075 - accuracy: 0.6686 - val_loss: 0.6138 - val_accuracy: 0.6316\n","Epoch 49/500\n","6/6 - 0s - loss: 0.6073 - accuracy: 0.6686\n","Epoch 50/500\n","6/6 - 1s - loss: 0.6059 - accuracy: 0.6686 - val_loss: 0.6117 - val_accuracy: 0.6316\n","Epoch 51/500\n","6/6 - 1s - loss: 0.6045 - accuracy: 0.6686\n","Epoch 52/500\n","6/6 - 1s - loss: 0.6044 - accuracy: 0.6686 - val_loss: 0.6115 - val_accuracy: 0.6316\n","Epoch 53/500\n","6/6 - 1s - loss: 0.6031 - accuracy: 0.6686\n","Epoch 54/500\n","6/6 - 1s - loss: 0.6021 - accuracy: 0.6686 - val_loss: 0.6073 - val_accuracy: 0.6316\n","Epoch 55/500\n","6/6 - 0s - loss: 0.6008 - accuracy: 0.6686\n","Epoch 56/500\n","6/6 - 1s - loss: 0.5998 - accuracy: 0.6686 - val_loss: 0.6005 - val_accuracy: 0.6316\n","Epoch 57/500\n","6/6 - 1s - loss: 0.5983 - accuracy: 0.6686\n","Epoch 58/500\n","6/6 - 1s - loss: 0.5973 - accuracy: 0.6686 - val_loss: 0.5980 - val_accuracy: 0.6316\n","Epoch 59/500\n","6/6 - 0s - loss: 0.5949 - accuracy: 0.6686\n","Epoch 60/500\n","6/6 - 1s - loss: 0.5929 - accuracy: 0.6686 - val_loss: 0.5906 - val_accuracy: 0.6316\n","Epoch 61/500\n","6/6 - 0s - loss: 0.5911 - accuracy: 0.6686\n","Epoch 62/500\n","6/6 - 1s - loss: 0.5895 - accuracy: 0.6686 - val_loss: 0.5809 - val_accuracy: 0.6316\n","Epoch 63/500\n","6/6 - 0s - loss: 0.5874 - accuracy: 0.6686\n","Epoch 64/500\n","6/6 - 1s - loss: 0.5841 - accuracy: 0.6686 - val_loss: 0.5718 - val_accuracy: 0.6316\n","Epoch 65/500\n","6/6 - 0s - loss: 0.5819 - accuracy: 0.6805\n","Epoch 66/500\n","6/6 - 1s - loss: 0.5765 - accuracy: 0.6805 - val_loss: 0.5613 - val_accuracy: 0.6316\n","Epoch 67/500\n","6/6 - 0s - loss: 0.5742 - accuracy: 0.6864\n","Epoch 68/500\n","6/6 - 1s - loss: 0.5688 - accuracy: 0.6923 - val_loss: 0.5495 - val_accuracy: 0.6316\n","Epoch 69/500\n","6/6 - 0s - loss: 0.5631 - accuracy: 0.6982\n","Epoch 70/500\n","6/6 - 1s - loss: 0.5596 - accuracy: 0.7337 - val_loss: 0.5211 - val_accuracy: 0.6842\n","Epoch 71/500\n","6/6 - 0s - loss: 0.5560 - accuracy: 0.7456\n","Epoch 72/500\n","6/6 - 0s - loss: 0.5565 - accuracy: 0.7396 - val_loss: 0.4991 - val_accuracy: 0.7895\n","Epoch 73/500\n","6/6 - 0s - loss: 0.5503 - accuracy: 0.7396\n","Epoch 74/500\n","6/6 - 0s - loss: 0.5601 - accuracy: 0.7278 - val_loss: 0.5068 - val_accuracy: 0.6842\n","Epoch 75/500\n","6/6 - 0s - loss: 0.5552 - accuracy: 0.7337\n","Epoch 76/500\n","6/6 - 0s - loss: 0.5445 - accuracy: 0.7456 - val_loss: 0.4752 - val_accuracy: 0.7895\n","Epoch 77/500\n","6/6 - 0s - loss: 0.5466 - accuracy: 0.7337\n","Epoch 78/500\n","6/6 - 0s - loss: 0.5425 - accuracy: 0.7574 - val_loss: 0.4588 - val_accuracy: 0.8421\n","Epoch 79/500\n","6/6 - 0s - loss: 0.5400 - accuracy: 0.7574\n","Epoch 80/500\n","6/6 - 0s - loss: 0.5478 - accuracy: 0.7278 - val_loss: 0.4500 - val_accuracy: 0.8421\n","Epoch 81/500\n","6/6 - 0s - loss: 0.5457 - accuracy: 0.7456\n","Epoch 82/500\n","6/6 - 0s - loss: 0.5419 - accuracy: 0.7456 - val_loss: 0.4504 - val_accuracy: 0.8421\n","Epoch 83/500\n","6/6 - 0s - loss: 0.5389 - accuracy: 0.7692\n","Epoch 84/500\n","6/6 - 0s - loss: 0.5392 - accuracy: 0.7751 - val_loss: 0.4546 - val_accuracy: 0.8421\n","Epoch 85/500\n","6/6 - 0s - loss: 0.5343 - accuracy: 0.7870\n","Epoch 86/500\n","6/6 - 0s - loss: 0.5338 - accuracy: 0.7811 - val_loss: 0.4356 - val_accuracy: 0.8421\n","Epoch 87/500\n","6/6 - 0s - loss: 0.5253 - accuracy: 0.7751\n","Epoch 88/500\n","6/6 - 0s - loss: 0.5254 - accuracy: 0.7633 - val_loss: 0.4319 - val_accuracy: 0.8947\n","Epoch 89/500\n","6/6 - 0s - loss: 0.5224 - accuracy: 0.7692\n","Epoch 90/500\n","6/6 - 0s - loss: 0.5214 - accuracy: 0.7751 - val_loss: 0.4365 - val_accuracy: 0.7895\n","Epoch 91/500\n","6/6 - 0s - loss: 0.5202 - accuracy: 0.7751\n","Epoch 92/500\n","6/6 - 0s - loss: 0.5497 - accuracy: 0.7278 - val_loss: 0.4175 - val_accuracy: 0.8947\n","Epoch 93/500\n","6/6 - 0s - loss: 0.5205 - accuracy: 0.7811\n","Epoch 94/500\n","6/6 - 0s - loss: 0.5195 - accuracy: 0.7870 - val_loss: 0.4387 - val_accuracy: 0.7895\n","Epoch 95/500\n","6/6 - 0s - loss: 0.5158 - accuracy: 0.7811\n","Epoch 96/500\n","6/6 - 0s - loss: 0.5162 - accuracy: 0.7811 - val_loss: 0.4883 - val_accuracy: 0.8421\n","Epoch 97/500\n","6/6 - 0s - loss: 0.5419 - accuracy: 0.7456\n","Epoch 98/500\n","6/6 - 0s - loss: 0.5142 - accuracy: 0.7811 - val_loss: 0.4663 - val_accuracy: 0.8421\n","Epoch 99/500\n","6/6 - 0s - loss: 0.5343 - accuracy: 0.7515\n","Epoch 100/500\n","6/6 - 0s - loss: 0.5483 - accuracy: 0.7278 - val_loss: 0.4199 - val_accuracy: 0.8421\n","Epoch 101/500\n","6/6 - 0s - loss: 0.5086 - accuracy: 0.7870\n","Epoch 102/500\n","6/6 - 0s - loss: 0.5148 - accuracy: 0.7870 - val_loss: 0.4193 - val_accuracy: 0.8421\n","Epoch 103/500\n","6/6 - 0s - loss: 0.5125 - accuracy: 0.7870\n","Epoch 104/500\n","6/6 - 0s - loss: 0.5822 - accuracy: 0.6805 - val_loss: 0.4131 - val_accuracy: 0.8421\n","Epoch 105/500\n","6/6 - 0s - loss: 0.5108 - accuracy: 0.7811\n","Epoch 106/500\n","6/6 - 0s - loss: 0.5150 - accuracy: 0.7811 - val_loss: 0.4441 - val_accuracy: 0.7895\n","Epoch 107/500\n","6/6 - 0s - loss: 0.5227 - accuracy: 0.7692\n","Epoch 108/500\n","6/6 - 0s - loss: 0.5166 - accuracy: 0.7751 - val_loss: 0.4149 - val_accuracy: 0.8421\n","Epoch 109/500\n","6/6 - 0s - loss: 0.5142 - accuracy: 0.7751\n","Epoch 110/500\n","6/6 - 0s - loss: 0.5506 - accuracy: 0.7278 - val_loss: 0.4206 - val_accuracy: 0.8421\n","Epoch 111/500\n","6/6 - 0s - loss: 0.5135 - accuracy: 0.7811\n","Epoch 112/500\n","6/6 - 0s - loss: 0.5196 - accuracy: 0.7692 - val_loss: 0.4342 - val_accuracy: 0.8421\n","Epoch 113/500\n","6/6 - 0s - loss: 0.5417 - accuracy: 0.7515\n","Epoch 114/500\n","6/6 - 0s - loss: 0.5443 - accuracy: 0.7160 - val_loss: 0.4378 - val_accuracy: 0.8421\n","Epoch 115/500\n","6/6 - 0s - loss: 0.5172 - accuracy: 0.7633\n","Epoch 116/500\n","6/6 - 0s - loss: 0.5210 - accuracy: 0.7633 - val_loss: 0.4344 - val_accuracy: 0.8421\n","Epoch 117/500\n","6/6 - 0s - loss: 0.5150 - accuracy: 0.7692\n","Epoch 118/500\n","6/6 - 0s - loss: 0.5137 - accuracy: 0.7811 - val_loss: 0.4083 - val_accuracy: 0.8421\n","Epoch 119/500\n","6/6 - 0s - loss: 0.5525 - accuracy: 0.7160\n","Epoch 120/500\n","6/6 - 0s - loss: 0.5153 - accuracy: 0.7692 - val_loss: 0.4157 - val_accuracy: 0.8421\n","Epoch 121/500\n","6/6 - 0s - loss: 0.5113 - accuracy: 0.7811\n","Epoch 122/500\n","6/6 - 0s - loss: 0.5128 - accuracy: 0.7751 - val_loss: 0.4120 - val_accuracy: 0.8421\n","Epoch 123/500\n","6/6 - 0s - loss: 0.5125 - accuracy: 0.7751\n","Epoch 124/500\n","6/6 - 0s - loss: 0.5361 - accuracy: 0.7515 - val_loss: 0.4113 - val_accuracy: 0.8421\n","Epoch 125/500\n","6/6 - 0s - loss: 0.5106 - accuracy: 0.7751\n","Epoch 126/500\n","6/6 - 0s - loss: 0.5133 - accuracy: 0.7751 - val_loss: 0.4228 - val_accuracy: 0.8421\n","Epoch 127/500\n","6/6 - 0s - loss: 0.5260 - accuracy: 0.7574\n","Epoch 128/500\n","6/6 - 0s - loss: 0.5076 - accuracy: 0.7515 - val_loss: 0.4286 - val_accuracy: 0.8421\n","Epoch 129/500\n","6/6 - 0s - loss: 0.5262 - accuracy: 0.7515\n","Epoch 130/500\n","6/6 - 0s - loss: 0.4992 - accuracy: 0.7692 - val_loss: 0.4286 - val_accuracy: 0.8421\n","Epoch 131/500\n","6/6 - 0s - loss: 0.5142 - accuracy: 0.7692\n","Epoch 132/500\n","6/6 - 0s - loss: 0.5110 - accuracy: 0.7692 - val_loss: 0.3995 - val_accuracy: 0.8421\n","Epoch 133/500\n","6/6 - 0s - loss: 0.5162 - accuracy: 0.7692\n","Epoch 134/500\n","6/6 - 0s - loss: 0.5198 - accuracy: 0.7633 - val_loss: 0.3966 - val_accuracy: 0.8421\n","Epoch 135/500\n","6/6 - 0s - loss: 0.5104 - accuracy: 0.7692\n","Epoch 136/500\n","6/6 - 0s - loss: 0.5089 - accuracy: 0.7751 - val_loss: 0.4037 - val_accuracy: 0.8421\n","Epoch 137/500\n","6/6 - 0s - loss: 0.5088 - accuracy: 0.7751\n","Epoch 138/500\n","6/6 - 0s - loss: 0.5082 - accuracy: 0.7751 - val_loss: 0.3940 - val_accuracy: 0.8421\n","Epoch 139/500\n","6/6 - 0s - loss: 0.5234 - accuracy: 0.7456\n","Epoch 140/500\n","6/6 - 0s - loss: 0.5077 - accuracy: 0.7751 - val_loss: 0.3942 - val_accuracy: 0.8421\n","Epoch 141/500\n","6/6 - 0s - loss: 0.5092 - accuracy: 0.7751\n","Epoch 142/500\n","6/6 - 0s - loss: 0.5444 - accuracy: 0.7278 - val_loss: 0.4839 - val_accuracy: 0.7895\n","Epoch 143/500\n","6/6 - 0s - loss: 0.5218 - accuracy: 0.7456\n","Epoch 144/500\n","6/6 - 0s - loss: 0.5106 - accuracy: 0.7811 - val_loss: 0.4222 - val_accuracy: 0.8421\n","Epoch 145/500\n","6/6 - 0s - loss: 0.5139 - accuracy: 0.7692\n","Epoch 146/500\n","6/6 - 0s - loss: 0.5135 - accuracy: 0.7633 - val_loss: 0.4649 - val_accuracy: 0.8421\n","Epoch 147/500\n","6/6 - 0s - loss: 0.5405 - accuracy: 0.7219\n","Epoch 148/500\n","6/6 - 0s - loss: 0.5120 - accuracy: 0.7692 - val_loss: 0.4196 - val_accuracy: 0.8421\n","Epoch 149/500\n","6/6 - 0s - loss: 0.5095 - accuracy: 0.7692\n","Epoch 150/500\n","6/6 - 0s - loss: 0.5046 - accuracy: 0.7811 - val_loss: 0.4063 - val_accuracy: 0.8421\n","Epoch 151/500\n","6/6 - 0s - loss: 0.5101 - accuracy: 0.7751\n","Epoch 152/500\n","6/6 - 0s - loss: 0.5100 - accuracy: 0.7692 - val_loss: 0.4116 - val_accuracy: 0.8421\n","Epoch 153/500\n","6/6 - 0s - loss: 0.5099 - accuracy: 0.7692\n","Epoch 154/500\n","6/6 - 0s - loss: 0.5090 - accuracy: 0.7751 - val_loss: 0.3975 - val_accuracy: 0.8421\n","Epoch 155/500\n","6/6 - 0s - loss: 0.5080 - accuracy: 0.7751\n","Epoch 156/500\n","6/6 - 0s - loss: 0.5061 - accuracy: 0.7751 - val_loss: 0.3884 - val_accuracy: 0.8421\n","Epoch 157/500\n","6/6 - 0s - loss: 0.5056 - accuracy: 0.7751\n","Epoch 158/500\n","6/6 - 0s - loss: 0.5040 - accuracy: 0.7751 - val_loss: 0.4576 - val_accuracy: 0.8421\n","Epoch 159/500\n","6/6 - 0s - loss: 0.5297 - accuracy: 0.7396\n","Epoch 160/500\n","6/6 - 0s - loss: 0.5034 - accuracy: 0.7751 - val_loss: 0.3951 - val_accuracy: 0.8421\n","Epoch 161/500\n","6/6 - 0s - loss: 0.5068 - accuracy: 0.7811\n","Epoch 162/500\n","6/6 - 0s - loss: 0.5112 - accuracy: 0.7870 - val_loss: 0.4033 - val_accuracy: 0.8421\n","Epoch 163/500\n","6/6 - 0s - loss: 0.5074 - accuracy: 0.7751\n","Epoch 164/500\n","6/6 - 0s - loss: 0.5078 - accuracy: 0.7692 - val_loss: 0.4048 - val_accuracy: 0.8421\n","Epoch 165/500\n","6/6 - 0s - loss: 0.5048 - accuracy: 0.7751\n","Epoch 166/500\n","6/6 - 0s - loss: 0.5008 - accuracy: 0.7751 - val_loss: 0.3978 - val_accuracy: 0.8421\n","Epoch 167/500\n","6/6 - 0s - loss: 0.5057 - accuracy: 0.7811\n","Epoch 168/500\n","6/6 - 0s - loss: 0.5059 - accuracy: 0.7751 - val_loss: 0.3963 - val_accuracy: 0.8421\n","Epoch 169/500\n","6/6 - 0s - loss: 0.5036 - accuracy: 0.7870\n","Epoch 170/500\n","6/6 - 0s - loss: 0.5018 - accuracy: 0.7870 - val_loss: 0.4474 - val_accuracy: 0.8421\n","Epoch 171/500\n","6/6 - 0s - loss: 0.5261 - accuracy: 0.7396\n","Epoch 172/500\n","6/6 - 0s - loss: 0.5083 - accuracy: 0.7692 - val_loss: 0.4152 - val_accuracy: 0.8421\n","Epoch 173/500\n","6/6 - 0s - loss: 0.5086 - accuracy: 0.7692\n","Epoch 174/500\n","6/6 - 0s - loss: 0.5023 - accuracy: 0.7811 - val_loss: 0.4043 - val_accuracy: 0.8947\n","Epoch 175/500\n","6/6 - 0s - loss: 0.5088 - accuracy: 0.7870\n","Epoch 176/500\n","6/6 - 0s - loss: 0.5096 - accuracy: 0.7870 - val_loss: 0.3945 - val_accuracy: 0.8421\n","Epoch 177/500\n","6/6 - 0s - loss: 0.5038 - accuracy: 0.7751\n","Epoch 178/500\n","6/6 - 0s - loss: 0.5069 - accuracy: 0.7692 - val_loss: 0.4010 - val_accuracy: 0.8421\n","Epoch 179/500\n","6/6 - 0s - loss: 0.5033 - accuracy: 0.7811\n","Epoch 180/500\n","6/6 - 0s - loss: 0.4976 - accuracy: 0.7811 - val_loss: 0.3861 - val_accuracy: 0.8421\n","Epoch 181/500\n","6/6 - 0s - loss: 0.5025 - accuracy: 0.7811\n","Epoch 182/500\n","6/6 - 0s - loss: 0.5025 - accuracy: 0.7811 - val_loss: 0.3844 - val_accuracy: 0.8421\n","Epoch 183/500\n","6/6 - 0s - loss: 0.5023 - accuracy: 0.7811\n","Epoch 184/500\n","6/6 - 0s - loss: 0.5022 - accuracy: 0.7811 - val_loss: 0.3875 - val_accuracy: 0.8421\n","Epoch 185/500\n","6/6 - 0s - loss: 0.5039 - accuracy: 0.7811\n","Epoch 186/500\n","6/6 - 0s - loss: 0.5024 - accuracy: 0.7811 - val_loss: 0.3976 - val_accuracy: 0.8421\n","Epoch 187/500\n","6/6 - 0s - loss: 0.5083 - accuracy: 0.7751\n","Epoch 188/500\n","6/6 - 0s - loss: 0.5045 - accuracy: 0.7751 - val_loss: 0.3954 - val_accuracy: 0.8421\n","Epoch 189/500\n","6/6 - 0s - loss: 0.5024 - accuracy: 0.7811\n","Epoch 190/500\n","6/6 - 0s - loss: 0.5051 - accuracy: 0.7811 - val_loss: 0.3931 - val_accuracy: 0.8421\n","Epoch 191/500\n","6/6 - 0s - loss: 0.5059 - accuracy: 0.7751\n","Epoch 192/500\n","6/6 - 0s - loss: 0.5018 - accuracy: 0.7811 - val_loss: 0.3900 - val_accuracy: 0.8421\n","Epoch 193/500\n","6/6 - 0s - loss: 0.5059 - accuracy: 0.7811\n","Epoch 194/500\n","6/6 - 0s - loss: 0.5005 - accuracy: 0.7811 - val_loss: 0.3978 - val_accuracy: 0.8421\n","Epoch 195/500\n","6/6 - 0s - loss: 0.5028 - accuracy: 0.7751\n","Epoch 196/500\n","6/6 - 0s - loss: 0.4986 - accuracy: 0.7811 - val_loss: 0.3848 - val_accuracy: 0.8421\n","Epoch 197/500\n","6/6 - 0s - loss: 0.5050 - accuracy: 0.7811\n","Epoch 198/500\n","6/6 - 0s - loss: 0.4967 - accuracy: 0.7811 - val_loss: 0.3977 - val_accuracy: 0.8421\n","Epoch 199/500\n","6/6 - 0s - loss: 0.5001 - accuracy: 0.7751\n","Epoch 200/500\n","6/6 - 0s - loss: 0.5000 - accuracy: 0.7811 - val_loss: 0.3808 - val_accuracy: 0.8947\n","Epoch 201/500\n","6/6 - 0s - loss: 0.4975 - accuracy: 0.7811\n","Epoch 202/500\n","6/6 - 0s - loss: 0.4969 - accuracy: 0.7811 - val_loss: 0.3747 - val_accuracy: 0.8947\n","Epoch 203/500\n","6/6 - 0s - loss: 0.4944 - accuracy: 0.7811\n","Epoch 204/500\n","6/6 - 0s - loss: 0.4963 - accuracy: 0.7811 - val_loss: 0.4027 - val_accuracy: 0.8421\n","Epoch 205/500\n","6/6 - 0s - loss: 0.5065 - accuracy: 0.7692\n","Epoch 206/500\n","6/6 - 0s - loss: 0.4946 - accuracy: 0.7811 - val_loss: 0.3688 - val_accuracy: 0.8947\n","Epoch 207/500\n","6/6 - 0s - loss: 0.4912 - accuracy: 0.7811\n","Epoch 208/500\n","6/6 - 0s - loss: 0.4974 - accuracy: 0.7751 - val_loss: 0.3592 - val_accuracy: 0.8947\n","Epoch 209/500\n","6/6 - 0s - loss: 0.4928 - accuracy: 0.7811\n","Epoch 210/500\n","6/6 - 0s - loss: 0.4907 - accuracy: 0.7811 - val_loss: 0.3665 - val_accuracy: 0.8947\n","Epoch 211/500\n","6/6 - 0s - loss: 0.4917 - accuracy: 0.7751\n","Epoch 212/500\n","6/6 - 0s - loss: 0.4945 - accuracy: 0.7692 - val_loss: 0.3720 - val_accuracy: 0.8947\n","Epoch 213/500\n","6/6 - 0s - loss: 0.4954 - accuracy: 0.7751\n","Epoch 214/500\n","6/6 - 0s - loss: 0.4895 - accuracy: 0.7811 - val_loss: 0.3682 - val_accuracy: 0.8947\n","Epoch 215/500\n","6/6 - 0s - loss: 0.4919 - accuracy: 0.7811\n","Epoch 216/500\n","6/6 - 0s - loss: 0.5007 - accuracy: 0.7751 - val_loss: 0.3657 - val_accuracy: 0.8947\n","Epoch 217/500\n","6/6 - 0s - loss: 0.4980 - accuracy: 0.7692\n","Epoch 218/500\n","6/6 - 0s - loss: 0.4912 - accuracy: 0.7692 - val_loss: 0.3550 - val_accuracy: 0.9474\n","Epoch 219/500\n","6/6 - 0s - loss: 0.4907 - accuracy: 0.7811\n","Epoch 220/500\n","6/6 - 0s - loss: 0.4884 - accuracy: 0.7811 - val_loss: 0.3546 - val_accuracy: 0.9474\n","Epoch 221/500\n","6/6 - 0s - loss: 0.4875 - accuracy: 0.7811\n","Epoch 222/500\n","6/6 - 0s - loss: 0.4901 - accuracy: 0.7574 - val_loss: 0.3513 - val_accuracy: 0.8947\n","Epoch 223/500\n","6/6 - 0s - loss: 0.4889 - accuracy: 0.7692\n","Epoch 224/500\n","6/6 - 0s - loss: 0.4853 - accuracy: 0.7751 - val_loss: 0.3355 - val_accuracy: 0.9474\n","Epoch 225/500\n","6/6 - 0s - loss: 0.4820 - accuracy: 0.7811\n","Epoch 226/500\n","6/6 - 0s - loss: 0.4787 - accuracy: 0.7811 - val_loss: 0.3382 - val_accuracy: 0.9474\n","Epoch 227/500\n","6/6 - 0s - loss: 0.4788 - accuracy: 0.7870\n","Epoch 228/500\n","6/6 - 0s - loss: 0.4737 - accuracy: 0.7870 - val_loss: 0.3375 - val_accuracy: 0.9474\n","Epoch 229/500\n","6/6 - 0s - loss: 0.4741 - accuracy: 0.7929\n","Epoch 230/500\n","6/6 - 0s - loss: 0.4756 - accuracy: 0.7870 - val_loss: 0.3105 - val_accuracy: 0.9474\n","Epoch 231/500\n","6/6 - 0s - loss: 0.4763 - accuracy: 0.7811\n","Epoch 232/500\n","6/6 - 0s - loss: 0.4788 - accuracy: 0.7870 - val_loss: 0.3089 - val_accuracy: 0.9474\n","Epoch 233/500\n","6/6 - 0s - loss: 0.4766 - accuracy: 0.7751\n","Epoch 234/500\n","6/6 - 0s - loss: 0.5075 - accuracy: 0.8047 - val_loss: 0.3289 - val_accuracy: 0.8947\n","Epoch 235/500\n","6/6 - 0s - loss: 0.4996 - accuracy: 0.7988\n","Epoch 236/500\n","6/6 - 0s - loss: 0.4802 - accuracy: 0.7811 - val_loss: 0.3657 - val_accuracy: 0.8947\n","Epoch 237/500\n","6/6 - 0s - loss: 0.4836 - accuracy: 0.7870\n","Epoch 238/500\n","6/6 - 0s - loss: 0.4762 - accuracy: 0.7811 - val_loss: 0.3515 - val_accuracy: 0.9474\n","Epoch 239/500\n","6/6 - 0s - loss: 0.4832 - accuracy: 0.7811\n","Epoch 240/500\n","6/6 - 0s - loss: 0.4801 - accuracy: 0.7811 - val_loss: 0.3362 - val_accuracy: 0.9474\n","Epoch 241/500\n","6/6 - 0s - loss: 0.4739 - accuracy: 0.7929\n","Epoch 242/500\n","6/6 - 0s - loss: 0.4721 - accuracy: 0.7929 - val_loss: 0.3199 - val_accuracy: 0.8947\n","Epoch 243/500\n","6/6 - 0s - loss: 0.4781 - accuracy: 0.7811\n","Epoch 244/500\n","6/6 - 0s - loss: 0.4779 - accuracy: 0.7811 - val_loss: 0.3116 - val_accuracy: 0.9474\n","Epoch 245/500\n","6/6 - 0s - loss: 0.4677 - accuracy: 0.8047\n","Epoch 246/500\n","6/6 - 0s - loss: 0.4855 - accuracy: 0.7988 - val_loss: 0.3168 - val_accuracy: 0.9474\n","Epoch 247/500\n","6/6 - 0s - loss: 0.4634 - accuracy: 0.8047\n","Epoch 248/500\n","6/6 - 0s - loss: 0.5289 - accuracy: 0.7751 - val_loss: 0.3439 - val_accuracy: 0.8421\n","Epoch 249/500\n","6/6 - 0s - loss: 0.4847 - accuracy: 0.8047\n","Epoch 250/500\n","6/6 - 0s - loss: 0.5430 - accuracy: 0.7988 - val_loss: 0.3672 - val_accuracy: 0.8947\n","Epoch 251/500\n","6/6 - 0s - loss: 0.4784 - accuracy: 0.7929\n","Epoch 252/500\n","6/6 - 0s - loss: 0.4888 - accuracy: 0.7692 - val_loss: 0.3782 - val_accuracy: 0.8421\n","Epoch 253/500\n","6/6 - 0s - loss: 0.4870 - accuracy: 0.7751\n","Epoch 254/500\n","6/6 - 0s - loss: 0.4908 - accuracy: 0.7692 - val_loss: 0.3692 - val_accuracy: 0.8421\n","Epoch 255/500\n","6/6 - 0s - loss: 0.4781 - accuracy: 0.7811\n","Epoch 256/500\n","6/6 - 0s - loss: 0.4851 - accuracy: 0.7692 - val_loss: 0.3585 - val_accuracy: 0.8947\n","Epoch 257/500\n","6/6 - 0s - loss: 0.4788 - accuracy: 0.7811\n","Epoch 258/500\n","6/6 - 0s - loss: 0.4810 - accuracy: 0.7811 - val_loss: 0.3301 - val_accuracy: 0.9474\n","Epoch 259/500\n","6/6 - 0s - loss: 0.4758 - accuracy: 0.7870\n","Epoch 260/500\n","6/6 - 0s - loss: 0.4798 - accuracy: 0.7811 - val_loss: 0.3273 - val_accuracy: 0.8947\n","Epoch 261/500\n","6/6 - 0s - loss: 0.4800 - accuracy: 0.7751\n","Epoch 262/500\n","6/6 - 0s - loss: 0.4750 - accuracy: 0.7870 - val_loss: 0.3261 - val_accuracy: 0.9474\n","Epoch 263/500\n","6/6 - 0s - loss: 0.4768 - accuracy: 0.7929\n","Epoch 264/500\n","6/6 - 0s - loss: 0.4777 - accuracy: 0.7929 - val_loss: 0.3221 - val_accuracy: 0.9474\n","Epoch 265/500\n","6/6 - 0s - loss: 0.4692 - accuracy: 0.7988\n","Epoch 266/500\n","6/6 - 0s - loss: 0.4693 - accuracy: 0.7988 - val_loss: 0.3142 - val_accuracy: 0.9474\n","Epoch 267/500\n","6/6 - 0s - loss: 0.4799 - accuracy: 0.7988\n","Epoch 268/500\n","6/6 - 0s - loss: 0.4626 - accuracy: 0.7988 - val_loss: 0.3316 - val_accuracy: 0.8947\n","Epoch 269/500\n","6/6 - 0s - loss: 0.4945 - accuracy: 0.8047\n","Epoch 270/500\n","6/6 - 0s - loss: 0.4757 - accuracy: 0.7988 - val_loss: 0.3711 - val_accuracy: 0.9474\n","Epoch 271/500\n","6/6 - 0s - loss: 0.4709 - accuracy: 0.7988\n","Epoch 272/500\n","6/6 - 0s - loss: 0.4788 - accuracy: 0.8166 - val_loss: 0.3744 - val_accuracy: 0.8421\n","Epoch 273/500\n","6/6 - 0s - loss: 0.4864 - accuracy: 0.7751\n","Epoch 274/500\n","6/6 - 0s - loss: 0.4775 - accuracy: 0.7811 - val_loss: 0.3189 - val_accuracy: 0.9474\n","Epoch 275/500\n","6/6 - 0s - loss: 0.4759 - accuracy: 0.7870\n","Epoch 276/500\n","6/6 - 0s - loss: 0.4662 - accuracy: 0.7988 - val_loss: 0.3174 - val_accuracy: 0.9474\n","Epoch 277/500\n","6/6 - 0s - loss: 0.4747 - accuracy: 0.7929\n","Epoch 278/500\n","6/6 - 0s - loss: 0.4668 - accuracy: 0.8107 - val_loss: 0.3701 - val_accuracy: 0.9474\n","Epoch 279/500\n","6/6 - 0s - loss: 0.4784 - accuracy: 0.8107\n","Epoch 280/500\n","6/6 - 0s - loss: 0.4579 - accuracy: 0.8107 - val_loss: 0.3503 - val_accuracy: 0.8421\n","Epoch 281/500\n","6/6 - 0s - loss: 0.4592 - accuracy: 0.8047\n","Epoch 282/500\n","6/6 - 0s - loss: 0.4563 - accuracy: 0.8107 - val_loss: 0.3295 - val_accuracy: 0.8947\n","Epoch 283/500\n","6/6 - 0s - loss: 0.4451 - accuracy: 0.8343\n","Epoch 284/500\n","6/6 - 0s - loss: 0.4552 - accuracy: 0.8225 - val_loss: 0.3037 - val_accuracy: 0.8947\n","Epoch 285/500\n","6/6 - 0s - loss: 0.4433 - accuracy: 0.8166\n","Epoch 286/500\n","6/6 - 0s - loss: 0.4471 - accuracy: 0.8047 - val_loss: 0.2887 - val_accuracy: 0.8947\n","Epoch 287/500\n","6/6 - 0s - loss: 0.4725 - accuracy: 0.8284\n","Epoch 288/500\n","6/6 - 0s - loss: 0.4487 - accuracy: 0.8225 - val_loss: 0.3225 - val_accuracy: 0.8421\n","Epoch 289/500\n","6/6 - 0s - loss: 0.4466 - accuracy: 0.8107\n","Epoch 290/500\n","6/6 - 0s - loss: 0.4628 - accuracy: 0.8225 - val_loss: 0.3138 - val_accuracy: 0.8947\n","Epoch 291/500\n","6/6 - 0s - loss: 0.4752 - accuracy: 0.8047\n","Epoch 292/500\n","6/6 - 0s - loss: 0.4995 - accuracy: 0.7692 - val_loss: 0.3043 - val_accuracy: 0.8947\n","Epoch 293/500\n","6/6 - 0s - loss: 0.5246 - accuracy: 0.8047\n","Epoch 294/500\n","6/6 - 0s - loss: 0.5094 - accuracy: 0.7929 - val_loss: 0.2885 - val_accuracy: 0.9474\n","Epoch 295/500\n","6/6 - 0s - loss: 0.4580 - accuracy: 0.7929\n","Epoch 296/500\n","6/6 - 0s - loss: 0.4714 - accuracy: 0.7870 - val_loss: 0.3141 - val_accuracy: 0.9474\n","Epoch 297/500\n","6/6 - 0s - loss: 0.4645 - accuracy: 0.7988\n","Epoch 298/500\n","6/6 - 0s - loss: 0.4601 - accuracy: 0.8166 - val_loss: 0.2981 - val_accuracy: 0.9474\n","Epoch 299/500\n","6/6 - 0s - loss: 0.4832 - accuracy: 0.8047\n","Epoch 300/500\n","6/6 - 0s - loss: 0.4501 - accuracy: 0.8107 - val_loss: 0.3299 - val_accuracy: 0.8947\n","Epoch 301/500\n","6/6 - 0s - loss: 0.4462 - accuracy: 0.8225\n","Epoch 302/500\n","6/6 - 0s - loss: 0.4683 - accuracy: 0.8166 - val_loss: 0.3171 - val_accuracy: 0.8947\n","Epoch 303/500\n","6/6 - 0s - loss: 0.4476 - accuracy: 0.8166\n","Epoch 304/500\n","6/6 - 0s - loss: 0.4400 - accuracy: 0.8107 - val_loss: 0.4159 - val_accuracy: 0.8421\n","Epoch 305/500\n","6/6 - 0s - loss: 0.4288 - accuracy: 0.8343\n","Epoch 306/500\n","6/6 - 0s - loss: 0.4382 - accuracy: 0.8047 - val_loss: 0.4120 - val_accuracy: 0.8421\n","Epoch 307/500\n","6/6 - 0s - loss: 0.4362 - accuracy: 0.8166\n","Epoch 308/500\n","6/6 - 0s - loss: 0.4326 - accuracy: 0.8166 - val_loss: 0.4390 - val_accuracy: 0.8947\n","Epoch 309/500\n","6/6 - 0s - loss: 0.4293 - accuracy: 0.8343\n","Epoch 310/500\n","6/6 - 0s - loss: 0.4359 - accuracy: 0.8166 - val_loss: 0.4226 - val_accuracy: 0.8421\n","Epoch 311/500\n","6/6 - 0s - loss: 0.4330 - accuracy: 0.8166\n","Epoch 312/500\n","6/6 - 0s - loss: 0.4706 - accuracy: 0.8225 - val_loss: 0.4130 - val_accuracy: 0.8947\n","Epoch 313/500\n","6/6 - 0s - loss: 0.4978 - accuracy: 0.7633\n","Epoch 314/500\n","6/6 - 0s - loss: 0.4456 - accuracy: 0.8225 - val_loss: 0.2973 - val_accuracy: 0.8947\n","Epoch 315/500\n","6/6 - 0s - loss: 0.4657 - accuracy: 0.7988\n","Epoch 316/500\n","6/6 - 0s - loss: 0.4970 - accuracy: 0.7811 - val_loss: 0.2753 - val_accuracy: 0.8947\n","Epoch 317/500\n","6/6 - 0s - loss: 0.4533 - accuracy: 0.8166\n","Epoch 318/500\n","6/6 - 0s - loss: 0.4654 - accuracy: 0.7988 - val_loss: 0.2817 - val_accuracy: 0.9474\n","Epoch 319/500\n","6/6 - 0s - loss: 0.5182 - accuracy: 0.7278\n","Epoch 320/500\n","6/6 - 0s - loss: 0.4705 - accuracy: 0.7988 - val_loss: 0.3585 - val_accuracy: 0.8421\n","Epoch 321/500\n","6/6 - 0s - loss: 0.4588 - accuracy: 0.8166\n","Epoch 322/500\n","6/6 - 0s - loss: 0.4531 - accuracy: 0.8166 - val_loss: 0.2803 - val_accuracy: 0.9474\n","Epoch 323/500\n","6/6 - 0s - loss: 0.4716 - accuracy: 0.7929\n","Epoch 324/500\n","6/6 - 0s - loss: 0.4534 - accuracy: 0.8047 - val_loss: 0.3206 - val_accuracy: 0.9474\n","Epoch 325/500\n","6/6 - 0s - loss: 0.4490 - accuracy: 0.8107\n","Epoch 326/500\n","6/6 - 0s - loss: 0.4602 - accuracy: 0.8107 - val_loss: 0.2953 - val_accuracy: 0.9474\n","Epoch 327/500\n","6/6 - 0s - loss: 0.5060 - accuracy: 0.7870\n","Epoch 328/500\n","6/6 - 0s - loss: 0.4372 - accuracy: 0.8284 - val_loss: 0.3515 - val_accuracy: 0.8421\n","Epoch 329/500\n","6/6 - 0s - loss: 0.4469 - accuracy: 0.8166\n","Epoch 330/500\n","6/6 - 0s - loss: 0.4418 - accuracy: 0.8107 - val_loss: 0.2828 - val_accuracy: 0.9474\n","Epoch 331/500\n","6/6 - 0s - loss: 0.4469 - accuracy: 0.8166\n","Epoch 332/500\n","6/6 - 0s - loss: 0.4487 - accuracy: 0.7988 - val_loss: 0.2820 - val_accuracy: 0.9474\n","Epoch 333/500\n","6/6 - 0s - loss: 0.4653 - accuracy: 0.8225\n","Epoch 334/500\n","6/6 - 0s - loss: 0.4659 - accuracy: 0.7988 - val_loss: 0.4343 - val_accuracy: 0.8421\n","Epoch 335/500\n","6/6 - 0s - loss: 0.4514 - accuracy: 0.8166\n","Epoch 336/500\n","6/6 - 0s - loss: 0.4830 - accuracy: 0.8107 - val_loss: 0.3615 - val_accuracy: 0.9474\n","Epoch 337/500\n","6/6 - 0s - loss: 0.4546 - accuracy: 0.8107\n","Epoch 338/500\n","6/6 - 0s - loss: 0.4266 - accuracy: 0.8225 - val_loss: 0.3065 - val_accuracy: 0.8421\n","Epoch 339/500\n","6/6 - 0s - loss: 0.4251 - accuracy: 0.8107\n","Epoch 340/500\n","6/6 - 0s - loss: 0.4230 - accuracy: 0.8166 - val_loss: 0.3099 - val_accuracy: 0.8421\n","Epoch 341/500\n","6/6 - 0s - loss: 0.4198 - accuracy: 0.8225\n","Epoch 342/500\n","6/6 - 0s - loss: 0.4262 - accuracy: 0.8166 - val_loss: 0.3005 - val_accuracy: 0.8421\n","Epoch 343/500\n","6/6 - 0s - loss: 0.4191 - accuracy: 0.8225\n","Epoch 344/500\n","6/6 - 0s - loss: 0.4087 - accuracy: 0.8225 - val_loss: 0.2986 - val_accuracy: 0.8421\n","Epoch 345/500\n","6/6 - 0s - loss: 0.4109 - accuracy: 0.8225\n","Epoch 346/500\n","6/6 - 0s - loss: 0.4139 - accuracy: 0.8284 - val_loss: 0.2707 - val_accuracy: 0.8421\n","Epoch 347/500\n","6/6 - 0s - loss: 0.4014 - accuracy: 0.8284\n","Epoch 348/500\n","6/6 - 0s - loss: 0.4192 - accuracy: 0.8166 - val_loss: 0.2848 - val_accuracy: 0.9474\n","Epoch 349/500\n","6/6 - 0s - loss: 0.4224 - accuracy: 0.8343\n","Epoch 350/500\n","6/6 - 0s - loss: 0.4072 - accuracy: 0.8225 - val_loss: 0.2919 - val_accuracy: 0.8421\n","Epoch 351/500\n","6/6 - 0s - loss: 0.4465 - accuracy: 0.8166\n","Epoch 352/500\n","6/6 - 0s - loss: 0.4596 - accuracy: 0.7929 - val_loss: 0.2754 - val_accuracy: 0.8947\n","Epoch 353/500\n","6/6 - 0s - loss: 0.4800 - accuracy: 0.8107\n","Epoch 354/500\n","6/6 - 0s - loss: 0.4563 - accuracy: 0.8107 - val_loss: 0.2772 - val_accuracy: 0.9474\n","Epoch 355/500\n","6/6 - 0s - loss: 0.4373 - accuracy: 0.8107\n","Epoch 356/500\n","6/6 - 0s - loss: 0.4261 - accuracy: 0.8225 - val_loss: 0.3883 - val_accuracy: 0.8421\n","Epoch 357/500\n","6/6 - 0s - loss: 0.4337 - accuracy: 0.8225\n","Epoch 358/500\n","6/6 - 0s - loss: 0.4410 - accuracy: 0.7929 - val_loss: 0.4175 - val_accuracy: 0.8421\n","Epoch 359/500\n","6/6 - 0s - loss: 0.4425 - accuracy: 0.8166\n","Epoch 360/500\n","6/6 - 0s - loss: 0.4408 - accuracy: 0.8107 - val_loss: 0.2746 - val_accuracy: 0.9474\n","Epoch 361/500\n","6/6 - 0s - loss: 0.5133 - accuracy: 0.7988\n","Epoch 362/500\n","6/6 - 0s - loss: 0.4426 - accuracy: 0.7988 - val_loss: 0.4431 - val_accuracy: 0.8421\n","Epoch 363/500\n","6/6 - 0s - loss: 0.4302 - accuracy: 0.8166\n","Epoch 364/500\n","6/6 - 0s - loss: 0.4630 - accuracy: 0.8343 - val_loss: 0.4573 - val_accuracy: 0.9474\n","Epoch 365/500\n","6/6 - 0s - loss: 0.4548 - accuracy: 0.8284\n","Epoch 366/500\n","6/6 - 0s - loss: 0.4285 - accuracy: 0.8284 - val_loss: 0.4439 - val_accuracy: 0.8421\n","Epoch 367/500\n","6/6 - 0s - loss: 0.4360 - accuracy: 0.8047\n","Epoch 368/500\n","6/6 - 0s - loss: 0.4472 - accuracy: 0.8166 - val_loss: 0.4348 - val_accuracy: 0.8947\n","Epoch 369/500\n","6/6 - 0s - loss: 0.4289 - accuracy: 0.8166\n","Epoch 370/500\n","6/6 - 0s - loss: 0.4808 - accuracy: 0.8343 - val_loss: 0.4178 - val_accuracy: 0.8947\n","Epoch 371/500\n","6/6 - 0s - loss: 0.4370 - accuracy: 0.8343\n","Epoch 372/500\n","6/6 - 0s - loss: 0.4135 - accuracy: 0.8284 - val_loss: 0.4142 - val_accuracy: 0.8947\n","Epoch 373/500\n","6/6 - 0s - loss: 0.4709 - accuracy: 0.8107\n","Epoch 374/500\n","6/6 - 0s - loss: 0.4290 - accuracy: 0.8343 - val_loss: 0.4297 - val_accuracy: 0.8947\n","Epoch 375/500\n","6/6 - 0s - loss: 0.4264 - accuracy: 0.8343\n","Epoch 376/500\n","6/6 - 0s - loss: 0.4834 - accuracy: 0.8343 - val_loss: 0.4159 - val_accuracy: 0.8947\n","Epoch 377/500\n","6/6 - 0s - loss: 0.4440 - accuracy: 0.8343\n","Epoch 378/500\n","6/6 - 0s - loss: 0.4539 - accuracy: 0.8166 - val_loss: 0.4355 - val_accuracy: 0.8421\n","Epoch 379/500\n","6/6 - 0s - loss: 0.4536 - accuracy: 0.8107\n","Epoch 380/500\n","6/6 - 0s - loss: 0.4259 - accuracy: 0.8343 - val_loss: 0.4471 - val_accuracy: 0.8421\n","Epoch 381/500\n","6/6 - 0s - loss: 0.4387 - accuracy: 0.8343\n","Epoch 382/500\n","6/6 - 0s - loss: 0.5072 - accuracy: 0.8225 - val_loss: 0.4331 - val_accuracy: 0.8421\n","Epoch 383/500\n","6/6 - 0s - loss: 0.4401 - accuracy: 0.8107\n","Epoch 384/500\n","6/6 - 0s - loss: 0.4402 - accuracy: 0.8225 - val_loss: 0.5600 - val_accuracy: 0.7895\n","Epoch 385/500\n","6/6 - 0s - loss: 0.4415 - accuracy: 0.8225\n","Epoch 386/500\n","6/6 - 0s - loss: 0.4364 - accuracy: 0.8284 - val_loss: 0.4033 - val_accuracy: 0.8947\n","Epoch 387/500\n","6/6 - 0s - loss: 0.4023 - accuracy: 0.8402\n","Epoch 388/500\n","6/6 - 0s - loss: 0.4035 - accuracy: 0.8343 - val_loss: 0.4007 - val_accuracy: 0.8421\n","Epoch 389/500\n","6/6 - 0s - loss: 0.4195 - accuracy: 0.8402\n","Epoch 390/500\n","6/6 - 0s - loss: 0.4329 - accuracy: 0.8225 - val_loss: 0.4035 - val_accuracy: 0.7895\n","Epoch 391/500\n","6/6 - 0s - loss: 0.4108 - accuracy: 0.8402\n","Epoch 392/500\n","6/6 - 0s - loss: 0.4133 - accuracy: 0.8462 - val_loss: 0.3945 - val_accuracy: 0.8421\n","Epoch 393/500\n","6/6 - 0s - loss: 0.4414 - accuracy: 0.8284\n","Epoch 394/500\n","6/6 - 0s - loss: 0.4209 - accuracy: 0.8225 - val_loss: 0.4120 - val_accuracy: 0.7895\n","Epoch 395/500\n","6/6 - 0s - loss: 0.4465 - accuracy: 0.8225\n","Epoch 396/500\n","6/6 - 0s - loss: 0.4558 - accuracy: 0.8047 - val_loss: 0.5101 - val_accuracy: 0.8421\n","Epoch 397/500\n","6/6 - 0s - loss: 0.4317 - accuracy: 0.8284\n","Epoch 398/500\n","6/6 - 0s - loss: 0.4542 - accuracy: 0.8166 - val_loss: 0.4031 - val_accuracy: 0.7895\n","Epoch 399/500\n","6/6 - 0s - loss: 0.4249 - accuracy: 0.8284\n","Epoch 400/500\n","6/6 - 0s - loss: 0.4413 - accuracy: 0.8284 - val_loss: 0.3794 - val_accuracy: 0.8947\n","Epoch 401/500\n","6/6 - 0s - loss: 0.4330 - accuracy: 0.8343\n","Epoch 402/500\n","6/6 - 0s - loss: 0.4304 - accuracy: 0.8284 - val_loss: 0.3640 - val_accuracy: 0.8947\n","Epoch 403/500\n","6/6 - 0s - loss: 0.4348 - accuracy: 0.8225\n","Epoch 404/500\n","6/6 - 0s - loss: 0.4177 - accuracy: 0.8284 - val_loss: 0.3467 - val_accuracy: 0.8421\n","Epoch 405/500\n","6/6 - 0s - loss: 0.4326 - accuracy: 0.8284\n","Epoch 406/500\n","6/6 - 0s - loss: 0.4180 - accuracy: 0.8284 - val_loss: 0.3479 - val_accuracy: 0.8947\n","Epoch 407/500\n","6/6 - 0s - loss: 0.4199 - accuracy: 0.8225\n","Epoch 408/500\n","6/6 - 0s - loss: 0.4131 - accuracy: 0.8225 - val_loss: 0.3481 - val_accuracy: 0.8947\n","Epoch 409/500\n","6/6 - 0s - loss: 0.4136 - accuracy: 0.8284\n","Epoch 410/500\n","6/6 - 0s - loss: 0.4361 - accuracy: 0.8166 - val_loss: 0.3570 - val_accuracy: 0.8421\n","Epoch 411/500\n","6/6 - 0s - loss: 0.4284 - accuracy: 0.8166\n","Epoch 412/500\n","6/6 - 0s - loss: 0.4167 - accuracy: 0.8343 - val_loss: 0.3572 - val_accuracy: 0.8947\n","Epoch 413/500\n","6/6 - 0s - loss: 0.4254 - accuracy: 0.8402\n","Epoch 414/500\n","6/6 - 0s - loss: 0.4188 - accuracy: 0.8343 - val_loss: 0.3617 - val_accuracy: 0.8947\n","Epoch 415/500\n","6/6 - 0s - loss: 0.4350 - accuracy: 0.8284\n","Epoch 416/500\n","6/6 - 0s - loss: 0.4295 - accuracy: 0.8225 - val_loss: 0.3392 - val_accuracy: 0.8421\n","Epoch 417/500\n","6/6 - 0s - loss: 0.4187 - accuracy: 0.8107\n","Epoch 418/500\n","6/6 - 0s - loss: 0.4210 - accuracy: 0.8225 - val_loss: 0.3993 - val_accuracy: 0.8421\n","Epoch 419/500\n","6/6 - 0s - loss: 0.4076 - accuracy: 0.8225\n","Epoch 420/500\n","6/6 - 0s - loss: 0.4225 - accuracy: 0.8343 - val_loss: 0.4021 - val_accuracy: 0.8421\n","Epoch 421/500\n","6/6 - 0s - loss: 0.4132 - accuracy: 0.8284\n","Epoch 422/500\n","6/6 - 0s - loss: 0.4048 - accuracy: 0.8284 - val_loss: 0.3924 - val_accuracy: 0.8421\n","Epoch 423/500\n","6/6 - 0s - loss: 0.4217 - accuracy: 0.8343\n","Epoch 424/500\n","6/6 - 0s - loss: 0.4130 - accuracy: 0.8343 - val_loss: 0.4377 - val_accuracy: 0.8421\n","Epoch 425/500\n","6/6 - 0s - loss: 0.4237 - accuracy: 0.8284\n","Epoch 426/500\n","6/6 - 0s - loss: 0.4247 - accuracy: 0.8284 - val_loss: 0.4105 - val_accuracy: 0.8421\n","Epoch 427/500\n","6/6 - 0s - loss: 0.4046 - accuracy: 0.8343\n","Epoch 428/500\n","6/6 - 0s - loss: 0.4247 - accuracy: 0.8343 - val_loss: 0.3756 - val_accuracy: 0.8421\n","Epoch 429/500\n","6/6 - 0s - loss: 0.4230 - accuracy: 0.8284\n","Epoch 430/500\n","6/6 - 0s - loss: 0.4163 - accuracy: 0.8343 - val_loss: 0.4227 - val_accuracy: 0.8421\n","Epoch 431/500\n","6/6 - 0s - loss: 0.4012 - accuracy: 0.8462\n","Epoch 432/500\n","6/6 - 0s - loss: 0.4383 - accuracy: 0.8166 - val_loss: 0.3627 - val_accuracy: 0.8947\n","Epoch 433/500\n","6/6 - 0s - loss: 0.4360 - accuracy: 0.8166\n","Epoch 434/500\n","6/6 - 0s - loss: 0.4067 - accuracy: 0.8343 - val_loss: 0.3787 - val_accuracy: 0.8947\n","Epoch 435/500\n","6/6 - 0s - loss: 0.4801 - accuracy: 0.8284\n","Epoch 436/500\n","6/6 - 0s - loss: 0.4210 - accuracy: 0.8166 - val_loss: 0.4200 - val_accuracy: 0.8421\n","Epoch 437/500\n","6/6 - 0s - loss: 0.4378 - accuracy: 0.8284\n","Epoch 438/500\n","6/6 - 0s - loss: 0.4096 - accuracy: 0.8402 - val_loss: 0.3650 - val_accuracy: 0.8947\n","Epoch 439/500\n","6/6 - 0s - loss: 0.3992 - accuracy: 0.8462\n","Epoch 440/500\n","6/6 - 0s - loss: 0.3891 - accuracy: 0.8462 - val_loss: 0.3540 - val_accuracy: 0.8947\n","Epoch 441/500\n","6/6 - 0s - loss: 0.3955 - accuracy: 0.8580\n","Epoch 442/500\n","6/6 - 0s - loss: 0.3902 - accuracy: 0.8580 - val_loss: 0.3782 - val_accuracy: 0.8947\n","Epoch 443/500\n","6/6 - 0s - loss: 0.3961 - accuracy: 0.8462\n","Epoch 444/500\n","6/6 - 0s - loss: 0.3932 - accuracy: 0.8580 - val_loss: 0.3501 - val_accuracy: 0.8947\n","Epoch 445/500\n","6/6 - 0s - loss: 0.4286 - accuracy: 0.8462\n","Epoch 446/500\n","6/6 - 0s - loss: 0.3947 - accuracy: 0.8462 - val_loss: 0.3469 - val_accuracy: 0.8947\n","Epoch 447/500\n","6/6 - 0s - loss: 0.4012 - accuracy: 0.8402\n","Epoch 448/500\n","6/6 - 0s - loss: 0.3985 - accuracy: 0.8462 - val_loss: 0.4058 - val_accuracy: 0.8947\n","Epoch 449/500\n","6/6 - 0s - loss: 0.4447 - accuracy: 0.8462\n","Epoch 450/500\n","6/6 - 0s - loss: 0.4095 - accuracy: 0.8521 - val_loss: 0.3776 - val_accuracy: 0.8947\n","Epoch 451/500\n","6/6 - 0s - loss: 0.3975 - accuracy: 0.8462\n","Epoch 452/500\n","6/6 - 0s - loss: 0.3906 - accuracy: 0.8462 - val_loss: 0.3619 - val_accuracy: 0.8947\n","Epoch 453/500\n","6/6 - 0s - loss: 0.3890 - accuracy: 0.8402\n","Epoch 454/500\n","6/6 - 0s - loss: 0.3953 - accuracy: 0.8521 - val_loss: 0.3694 - val_accuracy: 0.8947\n","Epoch 455/500\n","6/6 - 0s - loss: 0.4215 - accuracy: 0.8580\n","Epoch 456/500\n","6/6 - 0s - loss: 0.4795 - accuracy: 0.8047 - val_loss: 0.3516 - val_accuracy: 0.8947\n","Epoch 457/500\n","6/6 - 0s - loss: 0.3960 - accuracy: 0.8343\n","Epoch 458/500\n","6/6 - 0s - loss: 0.4346 - accuracy: 0.8284 - val_loss: 0.3478 - val_accuracy: 0.8947\n","Epoch 459/500\n","6/6 - 0s - loss: 0.4489 - accuracy: 0.8462\n","Epoch 460/500\n","6/6 - 0s - loss: 0.6040 - accuracy: 0.6568 - val_loss: 0.3488 - val_accuracy: 0.8947\n","Epoch 461/500\n","6/6 - 0s - loss: 0.4464 - accuracy: 0.8343\n","Epoch 462/500\n","6/6 - 0s - loss: 0.6189 - accuracy: 0.8284 - val_loss: 0.3540 - val_accuracy: 0.8421\n","Epoch 463/500\n","6/6 - 0s - loss: 0.4353 - accuracy: 0.8284\n","Epoch 464/500\n","6/6 - 0s - loss: 0.4325 - accuracy: 0.8343 - val_loss: 0.3610 - val_accuracy: 0.8947\n","Epoch 465/500\n","6/6 - 0s - loss: 0.4080 - accuracy: 0.8284\n","Epoch 466/500\n","6/6 - 0s - loss: 0.4520 - accuracy: 0.8521 - val_loss: 0.3670 - val_accuracy: 0.8947\n","Epoch 467/500\n","6/6 - 0s - loss: 0.4138 - accuracy: 0.8521\n","Epoch 468/500\n","6/6 - 0s - loss: 0.4074 - accuracy: 0.8402 - val_loss: 0.3550 - val_accuracy: 0.8947\n","Epoch 469/500\n","6/6 - 0s - loss: 0.4089 - accuracy: 0.8343\n","Epoch 470/500\n","6/6 - 0s - loss: 0.4031 - accuracy: 0.8580 - val_loss: 0.3790 - val_accuracy: 0.8947\n","Epoch 471/500\n","6/6 - 0s - loss: 0.4504 - accuracy: 0.8462\n","Epoch 472/500\n","6/6 - 0s - loss: 0.4261 - accuracy: 0.8284 - val_loss: 0.3311 - val_accuracy: 0.8947\n","Epoch 473/500\n","6/6 - 0s - loss: 0.4224 - accuracy: 0.8343\n","Epoch 474/500\n","6/6 - 0s - loss: 0.4200 - accuracy: 0.8225 - val_loss: 0.3350 - val_accuracy: 0.8947\n","Epoch 475/500\n","6/6 - 0s - loss: 0.4017 - accuracy: 0.8462\n","Epoch 476/500\n","6/6 - 0s - loss: 0.4114 - accuracy: 0.8521 - val_loss: 0.3688 - val_accuracy: 0.8947\n","Epoch 477/500\n","6/6 - 0s - loss: 0.3965 - accuracy: 0.8580\n","Epoch 478/500\n","6/6 - 0s - loss: 0.4728 - accuracy: 0.8462 - val_loss: 0.3391 - val_accuracy: 0.8947\n","Epoch 479/500\n","6/6 - 0s - loss: 0.4021 - accuracy: 0.8462\n","Epoch 480/500\n","6/6 - 0s - loss: 0.4116 - accuracy: 0.8402 - val_loss: 0.3457 - val_accuracy: 0.8947\n","Epoch 481/500\n","6/6 - 0s - loss: 0.4057 - accuracy: 0.8402\n","Epoch 482/500\n","6/6 - 0s - loss: 0.4024 - accuracy: 0.8462 - val_loss: 0.3231 - val_accuracy: 0.8947\n","Epoch 483/500\n","6/6 - 0s - loss: 0.4003 - accuracy: 0.8402\n","Epoch 484/500\n","6/6 - 0s - loss: 0.3958 - accuracy: 0.8462 - val_loss: 0.3868 - val_accuracy: 0.8947\n","Epoch 485/500\n","6/6 - 0s - loss: 0.4419 - accuracy: 0.8521\n","Epoch 486/500\n","6/6 - 0s - loss: 0.3999 - accuracy: 0.8462 - val_loss: 0.3185 - val_accuracy: 0.8947\n","Epoch 487/500\n","6/6 - 0s - loss: 0.3995 - accuracy: 0.8462\n","Epoch 488/500\n","6/6 - 0s - loss: 0.3967 - accuracy: 0.8402 - val_loss: 0.3170 - val_accuracy: 0.8947\n","Epoch 489/500\n","6/6 - 0s - loss: 0.4038 - accuracy: 0.8462\n","Epoch 490/500\n","6/6 - 0s - loss: 0.3993 - accuracy: 0.8521 - val_loss: 0.3535 - val_accuracy: 0.8947\n","Epoch 491/500\n","6/6 - 0s - loss: 0.3946 - accuracy: 0.8580\n","Epoch 492/500\n","6/6 - 0s - loss: 0.3972 - accuracy: 0.8521 - val_loss: 0.3279 - val_accuracy: 0.8947\n","Epoch 493/500\n","6/6 - 0s - loss: 0.4209 - accuracy: 0.8462\n","Epoch 494/500\n","6/6 - 0s - loss: 0.4497 - accuracy: 0.8166 - val_loss: 0.3835 - val_accuracy: 0.8947\n","Epoch 495/500\n","6/6 - 0s - loss: 0.4236 - accuracy: 0.8225\n","Epoch 496/500\n","6/6 - 0s - loss: 0.4059 - accuracy: 0.8462 - val_loss: 0.3306 - val_accuracy: 0.8947\n","Epoch 497/500\n","6/6 - 0s - loss: 0.3972 - accuracy: 0.8521\n","Epoch 498/500\n","6/6 - 0s - loss: 0.3836 - accuracy: 0.8580 - val_loss: 0.2943 - val_accuracy: 0.8947\n","Epoch 499/500\n","6/6 - 0s - loss: 0.3851 - accuracy: 0.8639\n","Epoch 500/500\n","6/6 - 0s - loss: 0.3990 - accuracy: 0.8521 - val_loss: 0.3438 - val_accuracy: 0.8947\n","Print Time for taining:  377.691072238\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"VhUFYc69jXif"},"source":[""],"execution_count":null,"outputs":[]}]}